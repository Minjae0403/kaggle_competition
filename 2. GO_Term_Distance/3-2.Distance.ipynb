{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eadbc80f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-08-20T04:48:56.891515Z",
     "iopub.status.busy": "2023-08-20T04:48:56.891141Z",
     "iopub.status.idle": "2023-08-20T04:49:00.477466Z",
     "shell.execute_reply": "2023-08-20T04:49:00.476528Z"
    },
    "papermill": {
     "duration": 3.600718,
     "end_time": "2023-08-20T04:49:00.479541",
     "exception": false,
     "start_time": "2023-08-20T04:48:56.878823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "USE_GPU = True\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    print('using device: cuda')\n",
    "else:\n",
    "    print('using device: cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "773e8f92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T04:49:00.502261Z",
     "iopub.status.busy": "2023-08-20T04:49:00.501716Z",
     "iopub.status.idle": "2023-08-20T04:49:00.629661Z",
     "shell.execute_reply": "2023-08-20T04:49:00.628858Z"
    },
    "papermill": {
     "duration": 0.141775,
     "end_time": "2023-08-20T04:49:00.631973",
     "exception": false,
     "start_time": "2023-08-20T04:49:00.490198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pickle\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557f3bc6",
   "metadata": {
    "papermill": {
     "duration": 0.010217,
     "end_time": "2023-08-20T04:49:00.652781",
     "exception": false,
     "start_time": "2023-08-20T04:49:00.642564",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b0823f",
   "metadata": {
    "papermill": {
     "duration": 0.010338,
     "end_time": "2023-08-20T04:49:00.673665",
     "exception": false,
     "start_time": "2023-08-20T04:49:00.663327",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- Train, Test의 단백질 종류 갯수 확인\n",
    "- 단백질 하나당 go term의 최대, 최소 갯수\n",
    "- 단백질 간 거리 벡터의 용량 확인 (142246 x )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919b3e73",
   "metadata": {
    "papermill": {
     "duration": 0.010331,
     "end_time": "2023-08-20T04:49:00.694774",
     "exception": false,
     "start_time": "2023-08-20T04:49:00.684443",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2ffc24b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T04:49:00.717920Z",
     "iopub.status.busy": "2023-08-20T04:49:00.717205Z",
     "iopub.status.idle": "2023-08-20T04:49:01.062788Z",
     "shell.execute_reply": "2023-08-20T04:49:01.061855Z"
    },
    "papermill": {
     "duration": 0.359582,
     "end_time": "2023-08-20T04:49:01.064735",
     "exception": false,
     "start_time": "2023-08-20T04:49:00.705153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "format-version: 1.2\n",
      "data-version: releases/2023-01-01\n",
      "subsetdef: chebi_ph7_3 \"Rhea list of ChEBI terms representing the major species at pH 7.3.\"\n",
      "subsetdef: gocheck_do_not_annotate \"Term not to be used for direct annotation\"\n",
      "subsetdef: gocheck_do_not_manually_annotate \"Term not to be used for direct manual annotation\"\n",
      "subsetdef: goslim_agr \"AGR slim\"\n",
      "subsetdef: goslim_aspergillus \"Aspergillus GO slim\"\n",
      "subsetdef: goslim_candida \"Candida GO slim\"\n",
      "subsetdef: goslim_chembl \"ChEMBL protein targets summary\"\n",
      "subsetdef: goslim_drosophila \"Drosophila GO slim\"\n",
      "subsetdef: goslim_flybase_ribbon \"FlyBase Drosophila GO ribbon slim\"\n",
      "subsetdef: goslim_generic \"Generic GO slim\"\n",
      "subsetdef: goslim_metagenomics \"Metagenomics GO slim\"\n",
      "subsetdef: goslim_mouse \"Mouse GO slim\"\n",
      "subsetdef: goslim_pir \"PIR GO slim\"\n",
      "subsetdef: goslim_plant \"Plant GO slim\"\n",
      "subsetdef: goslim_pombe \"Fission yeast GO slim\"\n",
      "subsetdef: goslim_synapse \"synapse GO slim\"\n",
      "subsetdef: goslim_yeast \"Yeast GO slim\"\n",
      "subsetdef: prokaryote_subset\n"
     ]
    }
   ],
   "source": [
    "#go-basic.obo\n",
    "\n",
    "obo_file_path = \"/kaggle/input/cafa-5-protein-function-prediction/Train/go-basic.obo\"\n",
    "\n",
    "with open(obo_file_path, \"r\") as obo_file:\n",
    "    obo_content = obo_file.read()\n",
    "\n",
    "# Print the first 1000 characters as an example\n",
    "print(obo_content[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ae14f3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T04:49:01.093029Z",
     "iopub.status.busy": "2023-08-20T04:49:01.092589Z",
     "iopub.status.idle": "2023-08-20T04:49:02.796106Z",
     "shell.execute_reply": "2023-08-20T04:49:02.794585Z"
    },
    "papermill": {
     "duration": 1.720573,
     "end_time": "2023-08-20T04:49:02.798300",
     "exception": false,
     "start_time": "2023-08-20T04:49:01.077727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">P20536 sp|P20536|UNG_VACCC Uracil-DNA glycosylase OS=Vaccinia virus (strain Copenhagen) OX=10249 GN=UNG PE=1 SV=1\n",
      "MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIPDKFFIQLKQPLRNK\n",
      "RVCVCGIDPYPKDGTGVPFESPNFTKKSIKEIASSISRLTGVIDYKGYNLNIIDGVIPWN\n",
      "YYLSCKLGETKSHAIYWDKISKLLLQHITKHVSVLYCLGKTDFSNIRAKLESPVTTIVGY\n",
      "HPAARDRQFEKDRSFEIINVLLELDNKVPINWAQGFIY\n",
      ">O73864 sp|O73864|WNT11_DANRE Protein Wnt-11 OS=Danio rerio OX=7955 GN=wnt11 PE=2 SV=1\n",
      "MTEYRNFLLLFITSLSVIYPCTGISWLGLTINGSSVGWNQTHHCKLLDGLVPDQQQLCKR\n",
      "NLELMHSIVRAARLTKSACTSSFSDMRWNWSSIESAPHFTPDLAKGTREAAFVVSLAAAV\n",
      "VSHAIARACASGDLPSCSCAAMPSEQAAPDFRWGGCGDNLRYYGLQMGSAFSDAPMRNRR\n",
      "SGPQDFRLMQLHNNAVGRQVLMDSLEMKCKCHGVSGSCSVKTCWKGLQDISTISADLKSK\n"
     ]
    }
   ],
   "source": [
    "# train_sequence.fast\n",
    "\n",
    "fasta_file_path = \"/kaggle/input/cafa-5-protein-function-prediction/Train/train_sequences.fasta\"\n",
    "\n",
    "with open(fasta_file_path, \"r\") as fasta_file:\n",
    "    lines = fasta_file.readlines()\n",
    "\n",
    "for line in lines[:10]:  \n",
    "    print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cd0da2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T04:49:02.823544Z",
     "iopub.status.busy": "2023-08-20T04:49:02.823160Z",
     "iopub.status.idle": "2023-08-20T04:49:04.670468Z",
     "shell.execute_reply": "2023-08-20T04:49:04.669053Z"
    },
    "papermill": {
     "duration": 1.862837,
     "end_time": "2023-08-20T04:49:04.673131",
     "exception": false,
     "start_time": "2023-08-20T04:49:02.810294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fasta 파일 중 ID, sequence data 불러오기\n",
    "fasta_file = '/kaggle/input/cafa-5-protein-function-prediction/Train/train_sequences.fasta'\n",
    "\n",
    "sequences = []\n",
    "for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "    sequence_id = record.id\n",
    "    sequence_data = record.seq\n",
    "    sequences.append((sequence_id, sequence_data))\n",
    "\n",
    "# sequences[0] : ('P20536', Seq('MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIPDKFFIQLK...FIY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a97602a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T04:49:04.696895Z",
     "iopub.status.busy": "2023-08-20T04:49:04.696520Z",
     "iopub.status.idle": "2023-08-20T04:49:07.368304Z",
     "shell.execute_reply": "2023-08-20T04:49:07.366638Z"
    },
    "papermill": {
     "duration": 2.686818,
     "end_time": "2023-08-20T04:49:07.370935",
     "exception": false,
     "start_time": "2023-08-20T04:49:04.684117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EntryID</th>\n",
       "      <th>term</th>\n",
       "      <th>aspect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A009IHW8</td>\n",
       "      <td>GO:0008152</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A009IHW8</td>\n",
       "      <td>GO:0034655</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A009IHW8</td>\n",
       "      <td>GO:0072523</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A009IHW8</td>\n",
       "      <td>GO:0044270</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A009IHW8</td>\n",
       "      <td>GO:0006753</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      EntryID        term aspect\n",
       "0  A0A009IHW8  GO:0008152    BPO\n",
       "1  A0A009IHW8  GO:0034655    BPO\n",
       "2  A0A009IHW8  GO:0072523    BPO\n",
       "3  A0A009IHW8  GO:0044270    BPO\n",
       "4  A0A009IHW8  GO:0006753    BPO"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_taxonomy.tsv, train_terms.tsv\n",
    "train_taxonomy = pd.read_csv(\"/kaggle/input/cafa-5-protein-function-prediction/Train/train_taxonomy.tsv\", sep= \"\\t\")\n",
    "train_terms = pd.read_csv(\"/kaggle/input/cafa-5-protein-function-prediction/Train/train_terms.tsv\", sep= \"\\t\") \n",
    "train_terms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "269a8d12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T04:49:07.394758Z",
     "iopub.status.busy": "2023-08-20T04:49:07.394406Z",
     "iopub.status.idle": "2023-08-20T04:49:08.114148Z",
     "shell.execute_reply": "2023-08-20T04:49:08.112848Z"
    },
    "papermill": {
     "duration": 0.734003,
     "end_time": "2023-08-20T04:49:08.116207",
     "exception": false,
     "start_time": "2023-08-20T04:49:07.382204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protein #: (142246,), term #: (31466,)\n"
     ]
    }
   ],
   "source": [
    "# 총 단백질 갯수 및 go term 갯수 확인\n",
    "print(\"Protein #: {}, term #: {}\".format(train_terms['EntryID'].unique().shape, train_terms['term'].unique().shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd547938",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T04:49:08.141932Z",
     "iopub.status.busy": "2023-08-20T04:49:08.140872Z",
     "iopub.status.idle": "2023-08-20T04:49:12.588653Z",
     "shell.execute_reply": "2023-08-20T04:49:12.587458Z"
    },
    "papermill": {
     "duration": 4.46291,
     "end_time": "2023-08-20T04:49:12.590652",
     "exception": false,
     "start_time": "2023-08-20T04:49:08.127742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_count min: 2, max: 815\n"
     ]
    }
   ],
   "source": [
    "# 하나의 단백질이 갖는 go term의 갯수 확인\n",
    "train_terms_collected = train_terms.groupby('EntryID')['term'].apply(list).reset_index(name='terms_collected')\n",
    "value_counts = train_terms_collected['terms_collected'].apply(len)\n",
    "\n",
    "'''\n",
    "value_counts = []\n",
    "for i in range(0, len(train_terms_collected)):\n",
    "    counts = len(train_terms_collected.loc[i, 'terms_collected'])\n",
    "    value_counts.append(counts)\n",
    "len(value_counts)\n",
    "'''\n",
    "train_terms_collected['value_counts'] = train_terms_collected['terms_collected'].apply(len)\n",
    "print(\"value_count min: {}, max: {}\".format(train_terms_collected['value_counts'].min(), train_terms_collected['value_counts'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ce934ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T04:49:12.614391Z",
     "iopub.status.busy": "2023-08-20T04:49:12.614050Z",
     "iopub.status.idle": "2023-08-20T04:49:25.408313Z",
     "shell.execute_reply": "2023-08-20T04:49:25.407066Z"
    },
    "papermill": {
     "duration": 12.808929,
     "end_time": "2023-08-20T04:49:25.410594",
     "exception": false,
     "start_time": "2023-08-20T04:49:12.601665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ems       ids# : 142246, embedding_dim : (142246, 1280)\n",
      "protbert  ids# : 142246, embedding_dim : (142246, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Embedding vector shape 비교\n",
    "\n",
    "ids_train_ems = np.load(\"/kaggle/input/cafa-5-ems-2-embeddings-numpy/train_ids.npy\")\n",
    "embeds_ems_train = np.load(\"/kaggle/input/cafa-5-ems-2-embeddings-numpy/train_embeddings.npy\")\n",
    "print(\"ems       ids# : {}, embedding_dim : {}\".format(len(ids_train_ems), embeds_ems_train.shape))\n",
    "\n",
    "ids_train_protbert = np.load(\"/kaggle/input/protbert-embeddings-for-cafa5/train_ids.npy\")\n",
    "embeds_protbert_train = np.load(\"/kaggle/input/protbert-embeddings-for-cafa5/train_embeddings.npy\")\n",
    "print(\"protbert  ids# : {}, embedding_dim : {}\".format(len(ids_train_protbert), embeds_protbert_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "450beccf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T04:49:25.434707Z",
     "iopub.status.busy": "2023-08-20T04:49:25.434292Z",
     "iopub.status.idle": "2023-08-20T04:49:25.441769Z",
     "shell.execute_reply": "2023-08-20T04:49:25.440277Z"
    },
    "papermill": {
     "duration": 0.02199,
     "end_time": "2023-08-20T04:49:25.443923",
     "exception": false,
     "start_time": "2023-08-20T04:49:25.421933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory consumed by array: 694.56 MB\n"
     ]
    }
   ],
   "source": [
    "# 메모리 확인 \n",
    "import numpy as np\n",
    "\n",
    "# Create a numpy array\n",
    "data = embeds_ems_train\n",
    "\n",
    "# Calculate the memory capacity consumed by the array\n",
    "memory_consumed_bytes = data.nbytes\n",
    "\n",
    "# Convert bytes to more human-readable format\n",
    "def format_bytes(size):\n",
    "    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:\n",
    "        if size < 1024.0:\n",
    "            return f\"{size:.2f} {unit}\"\n",
    "        size /= 1024.0\n",
    "    return f\"{size:.2f} PB\"\n",
    "\n",
    "memory_consumed_human_readable = format_bytes(memory_consumed_bytes)\n",
    "\n",
    "print(\"Memory consumed by array:\", memory_consumed_human_readable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde95100",
   "metadata": {
    "papermill": {
     "duration": 0.011466,
     "end_time": "2023-08-20T04:49:25.467126",
     "exception": false,
     "start_time": "2023-08-20T04:49:25.455660",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dd86624",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T04:49:25.492504Z",
     "iopub.status.busy": "2023-08-20T04:49:25.490430Z",
     "iopub.status.idle": "2023-08-20T04:49:25.504358Z",
     "shell.execute_reply": "2023-08-20T04:49:25.503293Z"
    },
    "papermill": {
     "duration": 0.028526,
     "end_time": "2023-08-20T04:49:25.506666",
     "exception": false,
     "start_time": "2023-08-20T04:49:25.478140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# testsuperset-taxon-list.tsv\n",
    "test_taxonomy = pd.read_csv(\"/kaggle/input/cafa-5-protein-function-prediction/Test (Targets)/testsuperset-taxon-list.tsv\", sep=\"\\t\", encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fb838d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T04:49:25.530299Z",
     "iopub.status.busy": "2023-08-20T04:49:25.529926Z",
     "iopub.status.idle": "2023-08-20T04:49:26.584819Z",
     "shell.execute_reply": "2023-08-20T04:49:26.583897Z"
    },
    "papermill": {
     "duration": 1.069011,
     "end_time": "2023-08-20T04:49:26.586971",
     "exception": false,
     "start_time": "2023-08-20T04:49:25.517960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Q9CQV8\t10090\n",
      "MTMDKSELVQKAKLAEQAERYDDMAAAMKAVTEQGHELSNEERNLLSVAYKNVVGARRSS\n",
      "WRVISSIEQKTERNEKKQQMGKEYREKIEAELQDICNDVLELLDKYLILNATQAESKVFY\n",
      "LKMKGDYFRYLSEVASGENKQTTVSNSQQAYQEAFEISKKEMQPTHPIRLGLALNFSVFY\n",
      "YEILNSPEKACSLAKTAFDEAIAELDTLNEESYKDSTLIMQLLRDNLTLWTSENQGDEGD\n",
      "AGEGEN\n",
      ">P62259\t10090\n",
      "MDDREDLVYQAKLAEQAERYDEMVESMKKVAGMDVELTVEERNLLSVAYKNVIGARRASW\n",
      "RIISSIEQKEENKGGEDKLKMIREYRQMVETELKLICCDILDVLDKHLIPAANTGESKVF\n",
      "YYKMKGDYHRYLAEFATGNDRKEAAENSLVAYKAASDIAMTELPPTHPIRLGLALNFSVF\n"
     ]
    }
   ],
   "source": [
    "# testsuperset.fasta\n",
    "fasta_file_path = \"/kaggle/input/cafa-5-protein-function-prediction/Test (Targets)/testsuperset.fasta\"\n",
    "\n",
    "with open(fasta_file_path, \"r\") as fasta_file:\n",
    "    lines = fasta_file.readlines()\n",
    "\n",
    "for line in lines[:10]:\n",
    "    print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81f911e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T04:49:26.613206Z",
     "iopub.status.busy": "2023-08-20T04:49:26.612849Z",
     "iopub.status.idle": "2023-08-20T04:49:28.632351Z",
     "shell.execute_reply": "2023-08-20T04:49:28.631149Z"
    },
    "papermill": {
     "duration": 2.03535,
     "end_time": "2023-08-20T04:49:28.634803",
     "exception": false,
     "start_time": "2023-08-20T04:49:26.599453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlen(sequences) 141865 인데, dictionary form으로 전환하면  141864가 나옴. \\n중복 데이터가 있다고 판단하여 아래 코드를 수행해봄\\n* 중복 데이터는 다른 사람이 만들어 놓은 embedding vector 갯수가 141854라 알게되었음.\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fasta 파일 중 ID, sequence data 불러오기\n",
    "fasta_file = '/kaggle/input/cafa-5-protein-function-prediction/Test (Targets)/testsuperset.fasta'\n",
    "\n",
    "sequences = []\n",
    "for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "    sequence_id = record.id\n",
    "    sequence_data = record.seq\n",
    "    sequences.append((sequence_id, sequence_data))\n",
    "\n",
    "# sequences[0] : ('P20536', Seq('MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIPDKFFIQLK...FIY'))\n",
    "\n",
    "'''\n",
    "len(sequences) 141865 인데, dictionary form으로 전환하면  141864가 나옴. \n",
    "중복 데이터가 있다고 판단하여 아래 코드를 수행해봄\n",
    "* 중복 데이터는 다른 사람이 만들어 놓은 embedding vector 갯수가 141854라 알게되었음.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "640b42ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T04:49:28.659486Z",
     "iopub.status.busy": "2023-08-20T04:49:28.659121Z",
     "iopub.status.idle": "2023-08-20T04:55:22.907553Z",
     "shell.execute_reply": "2023-08-20T04:55:22.906222Z"
    },
    "papermill": {
     "duration": 354.263661,
     "end_time": "2023-08-20T04:55:22.910126",
     "exception": false,
     "start_time": "2023-08-20T04:49:28.646465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141865/141865 [05:54<00:00, 400.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A0A1D6E0S8', Seq('MPSRSPACRPRGRNRRSAADAVARPLALALILVSTLPRAAHSQDLALPPVQPRG...SFC'))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 중복 데이터 확인 \n",
    "from tqdm import tqdm\n",
    "\n",
    "x = [] # 처음 등장한 값인지 판별하는 리스트\n",
    "new_a = [] # 중복된 원소만 넣는 리스트\n",
    "\n",
    "for i in tqdm(sequences):\n",
    "    if i not in x: \n",
    "        x.append(i)\n",
    "    else:\n",
    "        if i not in new_a: # 이미 중복 원소로 판정된 경우는 제외\n",
    "            new_a.append(i)\n",
    "\n",
    "print(new_a) # [1, 2] # 2회 이상 등장한 값들만 담긴 리스트\n",
    "# 중복 데이터: [('A0A1D6E0S8', Seq('MPSRSPACRPRGRNRRSAADAVARPLALALILVSTLPRAAHSQDLALPPVQPRG...SFC'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8e9878",
   "metadata": {
    "papermill": {
     "duration": 0.201199,
     "end_time": "2023-08-20T04:55:23.376555",
     "exception": false,
     "start_time": "2023-08-20T04:55:23.175356",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Go term 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7491248",
   "metadata": {
    "papermill": {
     "duration": 0.201547,
     "end_time": "2023-08-20T04:55:23.779666",
     "exception": false,
     "start_time": "2023-08-20T04:55:23.578119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Go term 예측 전략\n",
    "- 단백질 sequence vector간 거리가 가까울 수록 비슷한 단백질.\n",
    "- 비슷한 단백질을 하는 역할이 비슷함.\n",
    "- 단백질 간 거리가 가까우면 비슷한 go term을 공유한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde469d8",
   "metadata": {
    "papermill": {
     "duration": 0.199331,
     "end_time": "2023-08-20T04:55:24.179119",
     "exception": false,
     "start_time": "2023-08-20T04:55:23.979788",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Go term 예측 전략\n",
    "- 단백질 sequence vector간 거리가 가까울 수록 비슷한 단백질.\n",
    "- 비슷한 단백질을 하는 역할이 비슷함.\n",
    "- 단백질 간 거리가 가까우면 비슷한 go term을 공유한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfcbd40a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T04:55:24.640978Z",
     "iopub.status.busy": "2023-08-20T04:55:24.640367Z",
     "iopub.status.idle": "2023-08-20T04:55:24.656035Z",
     "shell.execute_reply": "2023-08-20T04:55:24.654825Z"
    },
    "papermill": {
     "duration": 0.278789,
     "end_time": "2023-08-20T04:55:24.657909",
     "exception": false,
     "start_time": "2023-08-20T04:55:24.379120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Consumption of the Tensor: 75.17 GB\n"
     ]
    }
   ],
   "source": [
    "# Train x Test (142246 * 141864) tensor 용량 계산\n",
    "import torch\n",
    "\n",
    "# Define the tensor shape and data type\n",
    "tensor_shape = (142246, 141864)\n",
    "data_type = torch.float32\n",
    "\n",
    "# Create a tensor of the specified shape and data type\n",
    "tensor = torch.empty(tensor_shape, dtype=data_type)\n",
    "\n",
    "# Calculate the memory consumption in bytes\n",
    "memory_bytes = tensor.element_size() * tensor.numel()\n",
    "\n",
    "# Convert bytes to gigabytes\n",
    "memory_gb = memory_bytes / (1024 ** 3)\n",
    "\n",
    "print(\"Memory Consumption of the Tensor: {:.2f} GB\".format(memory_gb))\n",
    "\n",
    "# Memory Consumption of the Tensor: 75.17 GB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cc245d",
   "metadata": {
    "papermill": {
     "duration": 0.198003,
     "end_time": "2023-08-20T04:55:25.053995",
     "exception": false,
     "start_time": "2023-08-20T04:55:24.855992",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Pickle 파일 만들기\n",
    "- Output 용량의 한계로 0 - 15k 까지만 만들었음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "baaa4a28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T04:55:25.457095Z",
     "iopub.status.busy": "2023-08-20T04:55:25.456450Z",
     "iopub.status.idle": "2023-08-20T04:55:25.685891Z",
     "shell.execute_reply": "2023-08-20T04:55:25.684370Z"
    },
    "papermill": {
     "duration": 0.432703,
     "end_time": "2023-08-20T04:55:25.688477",
     "exception": false,
     "start_time": "2023-08-20T04:55:25.255774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> 142246\n"
     ]
    }
   ],
   "source": [
    "# Data load\n",
    "ids_train = np.load(\"/kaggle/input/protbert-embeddings-for-cafa5/train_ids.npy\")\n",
    "embeds_protbert_train = np.load(\"/kaggle/input/protbert-embeddings-for-cafa5/train_embeddings.npy\")\n",
    "\n",
    "# Protein Id, embedding vectors dictionary\n",
    "dict_train_id_embeds = {}\n",
    "for i in zip(ids_train, embeds_protbert_train):\n",
    "    dict_train_id_embeds[i[0]] = i[1]\n",
    "print(type(dict_train_id_embeds), len(dict_train_id_embeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79d6314a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T04:55:26.090792Z",
     "iopub.status.busy": "2023-08-20T04:55:26.090154Z",
     "iopub.status.idle": "2023-08-20T04:55:32.629723Z",
     "shell.execute_reply": "2023-08-20T04:55:32.628538Z"
    },
    "papermill": {
     "duration": 6.743924,
     "end_time": "2023-08-20T04:55:32.631800",
     "exception": false,
     "start_time": "2023-08-20T04:55:25.887876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> 141864\n"
     ]
    }
   ],
   "source": [
    "# portbert embedding의 경우 141865개가 있다.\n",
    "# len(ids_test)와 dictionary의 key값이 달라 확인해봄*\n",
    "# 이는 중복된 ID가 있기 때문인데 실제 대회측에서 준 test ID 갯수도 141864개이다.\n",
    "# Data load\n",
    "ids_test = np.load(\"/kaggle/input/protbert-embeddings-for-cafa5/test_ids.npy\")\n",
    "embeds_protbert_test = np.load(\"/kaggle/input/protbert-embeddings-for-cafa5/test_embeddings.npy\")\n",
    "\n",
    "# Protein Id, embedding vectors dictionary\n",
    "dict_test_id_embeds = {}\n",
    "for i in zip(ids_test, embeds_protbert_test):\n",
    "    dict_test_id_embeds[i[0]] = i[1]\n",
    "print(type(dict_test_id_embeds), len(dict_test_id_embeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "901da339",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T04:55:33.041850Z",
     "iopub.status.busy": "2023-08-20T04:55:33.041470Z",
     "iopub.status.idle": "2023-08-20T04:55:33.929023Z",
     "shell.execute_reply": "2023-08-20T04:55:33.926983Z"
    },
    "papermill": {
     "duration": 1.093491,
     "end_time": "2023-08-20T04:55:33.931409",
     "exception": true,
     "start_time": "2023-08-20T04:55:32.837918",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Convert NumPy arrays to tensors\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m tensor_raw_data \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_data\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m tensor_raw_data_query \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(raw_data_query)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# GPU 위에 올렸으므로 ram위에 올라간 raw_data, raw_data_query를 지운다.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py:239\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "# Convert dictionary values to NumPy arrays\n",
    "raw_data = np.array(list(dict_train_id_embeds.values()))\n",
    "raw_data_query = np.array(list(dict_test_id_embeds.values()))\n",
    "\n",
    "# Convert NumPy arrays to tensors\n",
    "import torch\n",
    "\n",
    "tensor_raw_data = torch.tensor(raw_data).to('cuda')\n",
    "tensor_raw_data_query = torch.tensor(raw_data_query).to('cuda')\n",
    "\n",
    "# GPU 위에 올렸으므로 ram위에 올라간 raw_data, raw_data_query를 지운다.\n",
    "del raw_data\n",
    "del raw_data_query\n",
    "del dict_train_id_embeds\n",
    "del ids_train\n",
    "del embeds_protbert_train\n",
    "del dict_test_id_embeds\n",
    "del ids_test\n",
    "del embeds_protbert_test\n",
    "gc_collect = gc.collect()\n",
    "\n",
    "print(torch.cuda.is_available(), tensor_raw_data.is_cuda, tensor_raw_data_query.is_cuda)\n",
    "print(tensor_raw_data.shape, tensor_raw_data_query.shape)\n",
    "print(gc_collect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5e5578",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T07:30:55.586567Z",
     "iopub.status.busy": "2023-08-17T07:30:55.585948Z",
     "iopub.status.idle": "2023-08-17T07:30:57.890192Z",
     "shell.execute_reply": "2023-08-17T07:30:57.889127Z",
     "shell.execute_reply.started": "2023-08-17T07:30:55.586533Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "file_path = \"/kaggle/input/cafa-5-protein-function-prediction/Test (Targets)/testsuperset.fasta\"\n",
    "\n",
    "# Open the FASTA file and iterate through its records\n",
    "with open(file_path, \"r\") as fasta_file:\n",
    "    records = SeqIO.parse(fasta_file, \"fasta\")\n",
    "    \n",
    "    id_set = set()\n",
    "    for record in records:\n",
    "        # Add the record ID to the set\n",
    "        id_set.add(record.id)\n",
    "\n",
    "# Print the number of unique IDs\n",
    "num_ids = len(id_set)\n",
    "print(\"Number of unique IDs:\", num_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e7425f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T17:17:10.656744Z",
     "iopub.status.busy": "2023-08-19T17:17:10.656275Z",
     "iopub.status.idle": "2023-08-19T17:17:10.667599Z",
     "shell.execute_reply": "2023-08-19T17:17:10.666028Z",
     "shell.execute_reply.started": "2023-08-19T17:17:10.656709Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from IPython.display import FileLink, display\n",
    "\n",
    "def download_file(path, download_file_name):\n",
    "    os.chdir('/kaggle/working/')\n",
    "    zip_name = f\"/kaggle/working/{download_file_name}.zip\"\n",
    "    command = f\"zip {zip_name} {path} -r\"\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        print(\"Unable to run zip command!\")\n",
    "        print(result.stderr)\n",
    "        return\n",
    "    display(FileLink(f'{download_file_name}.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1edeed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T07:30:57.912787Z",
     "iopub.status.busy": "2023-08-17T07:30:57.912473Z",
     "iopub.status.idle": "2023-08-17T07:32:04.259543Z",
     "shell.execute_reply": "2023-08-17T07:32:04.258479Z",
     "shell.execute_reply.started": "2023-08-17T07:30:57.912761Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    batch_size_d = 5000\n",
    "    \n",
    "    pbar = tqdm(range(0, 20000, batch_size_d)) #len(tensor_raw_data)\n",
    "    \n",
    "    for i in pbar: #140000 , len(tensor_raw_data) : 142246\n",
    "        batch_data = tensor_raw_data[i:i+batch_size_d]\n",
    "        query_tensor = torch.cdist(batch_data, tensor_raw_data_query, p=2).cpu()\n",
    "        \n",
    "        distance_tensor_name = f'distance_tensor_{i}.pkl'\n",
    "        \n",
    "        with open(distance_tensor_name, 'wb') as f:\n",
    "            pickle.dump(query_tensor, f)\n",
    "        \n",
    "        print(distance_tensor_name)\n",
    "        \n",
    "        del query_tensor\n",
    "        del distance_tensor_name\n",
    "        torch.cuda.empty_cache()\n",
    "        collected = gc.collect()\n",
    "        print(f\"Garbage collector: collected {collected} objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b097b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T07:32:04.261540Z",
     "iopub.status.busy": "2023-08-17T07:32:04.261108Z",
     "iopub.status.idle": "2023-08-17T07:32:05.433078Z",
     "shell.execute_reply": "2023-08-17T07:32:05.431890Z",
     "shell.execute_reply.started": "2023-08-17T07:32:04.261508Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "torch.cuda.memory_allocated(), torch.cuda.max_memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56171847",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T08:02:19.680220Z",
     "iopub.status.busy": "2023-08-17T08:02:19.679153Z",
     "iopub.status.idle": "2023-08-17T08:05:17.300201Z",
     "shell.execute_reply": "2023-08-17T08:05:17.299028Z",
     "shell.execute_reply.started": "2023-08-17T08:02:19.680181Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "download_file('/kaggle/working/distance_tensor_15000.pkl', 'distance_tensor_15000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b20500",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T07:42:05.200359Z",
     "iopub.status.busy": "2023-08-17T07:42:05.199213Z",
     "iopub.status.idle": "2023-08-17T07:42:05.409445Z",
     "shell.execute_reply": "2023-08-17T07:42:05.408257Z",
     "shell.execute_reply.started": "2023-08-17T07:42:05.200320Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#del download_file('/kaggle/working/distance_tensor_0.pkl', 'distance_tensor_0')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330824a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T07:32:07.444654Z",
     "iopub.status.busy": "2023-08-17T07:32:07.444217Z",
     "iopub.status.idle": "2023-08-17T07:32:07.454744Z",
     "shell.execute_reply": "2023-08-17T07:32:07.453527Z",
     "shell.execute_reply.started": "2023-08-17T07:32:07.444620Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' \n",
    "download_file('/kaggle/working/distance_tensor_0.pkl', 'distance_tensor_0')\n",
    "download_file('/kaggle/working/distance_tensor_5000.pkl', 'distance_tensor_5000')\n",
    "download_file('/kaggle/working/distance_tensor_10000.pkl', 'distance_tensor_10000')\n",
    "download_file('/kaggle/working/distance_tensor_15000.pkl', 'distance_tensor_15000')\n",
    "download_file('/kaggle/working/distance_tensor_20000.pkl', 'distance_tensor_20000')\n",
    "download_file('/kaggle/working/distance_tensor_25000.pkl', 'distance_tensor_25000')\n",
    "download_file('/kaggle/working/distance_tensor_30000.pkl', 'distance_tensor_30000')\n",
    "download_file('/kaggle/working/distance_tensor_35000.pkl', 'distance_tensor_35000')\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a37125",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T07:32:07.456953Z",
     "iopub.status.busy": "2023-08-17T07:32:07.456334Z",
     "iopub.status.idle": "2023-08-17T07:32:26.964154Z",
     "shell.execute_reply": "2023-08-17T07:32:26.962684Z",
     "shell.execute_reply.started": "2023-08-17T07:32:07.456920Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pickle_file_path = '/kaggle/working/distance_tensor_0.pkl'\n",
    "\n",
    "# Load the pickle file\n",
    "with open(pickle_file_path, 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "\n",
    "# Now you can use the loaded_data as needed\n",
    "print(loaded_data, loaded_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085dbe9a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Pickle 파일 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6835fb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T12:37:25.697507Z",
     "iopub.status.busy": "2023-08-17T12:37:25.697037Z",
     "iopub.status.idle": "2023-08-17T12:37:50.077283Z",
     "shell.execute_reply": "2023-08-17T12:37:50.075741Z",
     "shell.execute_reply.started": "2023-08-17T12:37:25.697472Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "'''\n",
    "file_path_1 = '/kaggle/input/distance-tensor-0to20k/distance_tensor_0.pkl'\n",
    "with open(file_path_1, 'rb') as file:\n",
    "    distance_tensor_0 = pickle.load(file)\n",
    "\n",
    "file_path_2 = '/kaggle/input/distance-tensor-0to20k/distance_tensor_5000.pkl'\n",
    "with open(file_path_2, 'rb') as file:\n",
    "    distance_tensor_5000 = pickle.load(file)\n",
    "        \n",
    "file_path_1 = '/kaggle/input/distance-tensor-0to20k/distance_tensor_15000.pkl'\n",
    "with open(file_path_1, 'rb') as file:\n",
    "    distance_tensor_15000 = pickle.load(file) \n",
    "'''\n",
    "\n",
    "file_path_1 = '/kaggle/input/distance-tensor-0to20k/distance_tensor_10000.pkl'\n",
    "with open(file_path_1, 'rb') as file:\n",
    "    distance_tensor_10000 = pickle.load(file)\n",
    "\n",
    "   \n",
    "#print(distance_tensor_0.shape, distance_tensor_5000.shape)\n",
    "print(distance_tensor_10000.shape)\n",
    "#print(distance_tensor_15000.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406788fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T12:38:38.215258Z",
     "iopub.status.busy": "2023-08-17T12:38:38.214698Z",
     "iopub.status.idle": "2023-08-17T12:38:42.174465Z",
     "shell.execute_reply": "2023-08-17T12:38:42.172910Z",
     "shell.execute_reply.started": "2023-08-17T12:38:38.215217Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#distance_tensor_0to10k = torch.cat((distance_tensor_0, distance_tensor_5000), dim=0)\n",
    "distance_tensor_0to15k = torch.cat((distance_tensor_0to10k, distance_tensor_10000), dim=0)\n",
    "#distance_tensor_0to20k = torch.cat((distance_tensor_0to15k, distance_tensor_15000), dim=0)\n",
    "\n",
    "#print(distance_tensor_0to10k.shape)\n",
    "print(distance_tensor_0to15k.shape)\n",
    "#print(distance_tensor_0to20k.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242c89b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T05:02:24.758907Z",
     "iopub.status.busy": "2023-08-19T05:02:24.758509Z",
     "iopub.status.idle": "2023-08-19T05:02:24.764441Z",
     "shell.execute_reply": "2023-08-19T05:02:24.763229Z",
     "shell.execute_reply.started": "2023-08-19T05:02:24.758876Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#del distance_tensor_5000\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41626b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T12:41:27.790745Z",
     "iopub.status.busy": "2023-08-17T12:41:27.790248Z",
     "iopub.status.idle": "2023-08-17T12:42:06.644954Z",
     "shell.execute_reply": "2023-08-17T12:42:06.643710Z",
     "shell.execute_reply.started": "2023-08-17T12:41:27.790704Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = 'distance_tensor_0to15k.pkl'\n",
    "\n",
    "# Save the data to a pickle file\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(distance_tensor_0to15k, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca33363",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T12:43:01.158812Z",
     "iopub.status.busy": "2023-08-17T12:43:01.158374Z",
     "iopub.status.idle": "2023-08-17T12:53:16.371081Z",
     "shell.execute_reply": "2023-08-17T12:53:16.370137Z",
     "shell.execute_reply.started": "2023-08-17T12:43:01.158778Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "download_file('/kaggle/working/distance_tensor_0to15k.pkl', 'distance_tensor_0to15k.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230e6e6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T12:14:55.460707Z",
     "iopub.status.busy": "2023-08-17T12:14:55.460145Z",
     "iopub.status.idle": "2023-08-17T12:28:03.021953Z",
     "shell.execute_reply": "2023-08-17T12:28:03.020023Z",
     "shell.execute_reply.started": "2023-08-17T12:14:55.460660Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!zip -r file.zip /kaggle/working/distance_tensor_0to20k.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7668c863",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tensor 자르고 붙이는 연습\n",
    "'''\n",
    "#garbage collector가 gpu에서 삭제\n",
    "#no grad 적용/ # tensor_raw_data_query 쪼개서 이중 for문으로 만들기\n",
    "#garbage collector가 gpu에서 삭제\n",
    "\n",
    "with torch.no_grad():\n",
    "    result_tensor_1 = []\n",
    "    \n",
    "    batch_size_d = 100\n",
    "    batch_size_q = 100\n",
    "    \n",
    "    pbar = tqdm(range (5000,10000, batch_size_d))\n",
    "    for i in pbar:\n",
    "        batch_data = tensor_raw_data[i:i+batch_size_d]\n",
    "        query_tensor = [] # query_tensor는 비워줘야 한다.\n",
    "        \n",
    "        for j in range(0,len(tensor_raw_data_query), batch_size_q):\n",
    "            batch_query = tensor_raw_data_query[j:j+batch_size_q]\n",
    "            distance_query_seg = torch.cdist(batch_data, batch_query, p=2)\n",
    "            query_tensor.append(distance_query_seg)\n",
    "            \n",
    "        distance_data_seg = torch.cat(query_tensor, dim=1)#.cpu()\n",
    "        result_tensor_1.append(distance_data_seg)\n",
    "        \n",
    "    pbar.close()\n",
    "    distance_tensor_2 = torch.cat(result_tensor_1, dim=0)#.cpu()\n",
    "    #print(\"distance_tensor_1:\", distance_tensor_1)\n",
    "\n",
    "with open('distance_tensor_2.pkl', 'wb') as f:\n",
    "\tpickle.dump(distance_tensor_2, f)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95308a5b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Embedding vector 거리 구하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ae5d0e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "- goPreSim에서 구한 방식으로는 computing 능력이 부족하여 할 수 가 없음.\n",
    "- 따라서, torch에서 batch로 나누어 약 14만 개중 2만개의 train protein vector와 약 14만개의 test vector간의 거리를 구함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fbff8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T01:16:12.250874Z",
     "iopub.status.busy": "2023-08-20T01:16:12.250375Z",
     "iopub.status.idle": "2023-08-20T01:18:13.186926Z",
     "shell.execute_reply": "2023-08-20T01:18:13.185268Z",
     "shell.execute_reply.started": "2023-08-20T01:16:12.250830Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Distance vector loading\n",
    "file_path = '/kaggle/input/distance-tensor-con-0to15k/distance_tensor_0to15k.pkl'\n",
    "\n",
    "with open(file_path, 'rb') as file:\n",
    "    distance_tensor_0to15k = pickle.load(file)\n",
    "print(distance_tensor_0to15k.shape, distance_tensor_0to15k.min(), distance_tensor_0to15k.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bcdab2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T01:18:13.190056Z",
     "iopub.status.busy": "2023-08-20T01:18:13.189613Z",
     "iopub.status.idle": "2023-08-20T01:18:13.387120Z",
     "shell.execute_reply": "2023-08-20T01:18:13.385949Z",
     "shell.execute_reply.started": "2023-08-20T01:18:13.189995Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test data의 단백질 id loading\n",
    "ids_test = np.load(\"/kaggle/input/protbert-embeddings-for-cafa5/test_ids.npy\")\n",
    "ids_test_dict = {}\n",
    "for id_test in ids_test:\n",
    "    ids_test_dict[id_test] = 0\n",
    "len(ids_test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b488433",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T01:18:13.389606Z",
     "iopub.status.busy": "2023-08-20T01:18:13.388479Z",
     "iopub.status.idle": "2023-08-20T01:18:13.498355Z",
     "shell.execute_reply": "2023-08-20T01:18:13.497205Z",
     "shell.execute_reply.started": "2023-08-20T01:18:13.389563Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# index로 단백질 id를 찾을 수 있게 해주는 사전\n",
    "ids_train = np.load(\"/kaggle/input/protbert-embeddings-for-cafa5/train_ids.npy\")\n",
    "ids_train_list = ids_train[:15000]\n",
    "ids_train_numbering = {}\n",
    "for i in range(0,len(ids_train_list)):\n",
    "    ids_train_numbering[i] = ids_train[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaecdcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T01:18:13.501973Z",
     "iopub.status.busy": "2023-08-20T01:18:13.501516Z",
     "iopub.status.idle": "2023-08-20T01:18:14.577831Z",
     "shell.execute_reply": "2023-08-20T01:18:14.576721Z",
     "shell.execute_reply.started": "2023-08-20T01:18:13.501931Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Distance vector loading\n",
    "file_path = '/kaggle/input/dict-train-id-goterm/dict_train_id_go_term'\n",
    "\n",
    "with open(file_path, 'rb') as file:\n",
    "    dict_train_id_go_term = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04679891",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T01:18:14.579890Z",
     "iopub.status.busy": "2023-08-20T01:18:14.579446Z",
     "iopub.status.idle": "2023-08-20T01:18:23.566744Z",
     "shell.execute_reply": "2023-08-20T01:18:23.565395Z",
     "shell.execute_reply.started": "2023-08-20T01:18:14.579848Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# goPredSim Data: \n",
    "!git clone https://github.com/Rostlab/goPredSim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b56d39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T01:18:23.569845Z",
     "iopub.status.busy": "2023-08-20T01:18:23.569385Z",
     "iopub.status.idle": "2023-08-20T01:19:06.746323Z",
     "shell.execute_reply": "2023-08-20T01:19:06.745051Z",
     "shell.execute_reply.started": "2023-08-20T01:18:23.569795Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# goPredSim에서 만든 코드를 이용해 parents go term을 불러오기 위한 함수 loading\n",
    "import sys\n",
    "sys.path.append('/kaggle/working/goPredSim')\n",
    "from gene_ontology import GeneOntology\n",
    "\n",
    "onto_file = \"/kaggle/input/cafa-5-protein-function-prediction/Train/go-basic.obo\"\n",
    "go = GeneOntology(onto_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc778e9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T01:19:16.252421Z",
     "iopub.status.busy": "2023-08-20T01:19:16.251268Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 현재 문제점: 연산이 너무 느림 -> gpu 연산으로 해결하는 방법이 있을 것 같다.\n",
    "# ### dist에 들어갈 tensor를 변경 'dists = distance_tensor_0to15k[:,i].tolist()'\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "predictions = defaultdict(defaultdict)\n",
    "hit_ids = defaultdict(defaultdict)\n",
    "hits = [0.7] \n",
    "\n",
    "for i in tqdm(range(80000, len(ids_test_dict))): #(0:80000), (80000,len(ids_test_dict))\n",
    "    query = ids_test[i].split()[0] #ids_test[i] 이렇게만 해도 되나 일단 원본을 최대한 유지\n",
    "    dists = distance_tensor_0to15k[:,i].tolist()  \n",
    "    dists = np.array(dists)\n",
    "    \n",
    "    for h in hits:\n",
    "        prediction = dict() #line by line으로 만들 때는 prediction = dict(hits)에러가 난다.\n",
    "        \n",
    "        h = float(h)\n",
    "        indices = np.nonzero(dists <= h)[0] #[0]이 없으면 array(,형태로나옴)\n",
    "\n",
    "        '''\n",
    "        h = int(h)\n",
    "        indices_tmp = np.argpartition(dists, h)[0:h]\n",
    "        dists_tmp = [dists[i] for i in indices_tmp]\n",
    "        max_dist = np.amax(dists_tmp)\n",
    "        indices = np.nonzero(dists <= max_dist)[0]\n",
    "\n",
    "        '''\n",
    "                \n",
    "        num_hits = len(indices)\n",
    "        \n",
    "        for ind in indices:\n",
    "            lookup_id = ids_train_numbering[ind]        #self.lookup_db.ids[ind]  # ids_train_numbering\n",
    "            go_terms = dict_train_id_go_term[lookup_id]\n",
    "            dist = dists[ind]                                #self.go_db[lookup_id]\n",
    "            dist = 0.5 / (0.5 + dist)\n",
    "            \n",
    "            for g in go_terms:\n",
    "                if g in prediction.keys():\n",
    "                    prediction[g] += dist/num_hits\n",
    "                else:\n",
    "                    prediction[g] = dist/num_hits\n",
    "            \n",
    "            if query not in hit_ids[h].keys():\n",
    "        \n",
    "                hit_ids[h][query] = dict() #  h 값과 query 값으로 중첩된 딕셔너리 구조가 생성\n",
    "                hit_ids[h][query][lookup_id] = round(dist, 2) # 소수 둘째 자리 까지 반올림 하여 저장!\n",
    "\n",
    "         # 낮은 확률 삭제\n",
    "        keys_for_deletion = set()\n",
    "        for p in prediction:\n",
    "            ri = round(float(prediction[p]), 2) # 은 현재 키에 해당하는 값을 반올림하여 ri 변수에 할당\n",
    "            if ri == 0.00:\n",
    "                keys_for_deletion.add(p)\n",
    "            else:\n",
    "                prediction[p] = ri\n",
    "\n",
    "        for k in keys_for_deletion:\n",
    "            del prediction[k]\n",
    "\n",
    "        # 부모 go term을 삭제 하는 이유: 더 정확한 예측을 위해서 삭제한다.!\n",
    "        parent_terms = []\n",
    "        for p in prediction.keys():\n",
    "            parents = go.get_parent_terms(p) # 이 함수는 가지고 와야함\n",
    "            parent_terms += parents\n",
    "\n",
    "        keys_for_deletion = set()\n",
    "        for p in prediction.keys():\n",
    "            if p in parent_terms:\n",
    "                keys_for_deletion.add(p)\n",
    "\n",
    "        for k in keys_for_deletion:\n",
    "            del prediction[k]\n",
    "\n",
    "        predictions[h][query] = prediction \n",
    "\n",
    "tqdm.close\n",
    "\n",
    "print(predictions, hit_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f57828a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "7만개 = 10 기가 2 시간 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea27121",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T03:09:52.085169Z",
     "iopub.status.busy": "2023-08-20T03:09:52.083862Z",
     "iopub.status.idle": "2023-08-20T03:10:16.744834Z",
     "shell.execute_reply": "2023-08-20T03:10:16.743717Z",
     "shell.execute_reply.started": "2023-08-20T03:09:52.085120Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_file = \"/kaggle/working/submission_2 .tsv\"  # Change extension to .tsv\n",
    "\n",
    "try:\n",
    "    with open(out_file, 'w') as out:\n",
    "        for p in predictions.keys():\n",
    "            prediction = predictions[p]\n",
    "            for protein_ID in prediction.keys():  # prediction.keys() == protein_IDs \n",
    "                go_terms_ri = prediction[protein_ID]\n",
    "                for go_term in go_terms_ri.keys():\n",
    "                    ri = go_terms_ri[go_term]\n",
    "                    out.write('{}\\t{}\\t'.format(protein_ID, go_term))  # protein_ID, go_term\n",
    "                    out.write('{:0.2f}\\n'.format(float(ri)))  # ri probability\n",
    "    print(f\"Data written to '{out_file}' successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed85af63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T03:22:38.323762Z",
     "iopub.status.busy": "2023-08-20T03:22:38.322817Z",
     "iopub.status.idle": "2023-08-20T03:22:41.492181Z",
     "shell.execute_reply": "2023-08-20T03:22:41.490763Z",
     "shell.execute_reply.started": "2023-08-20T03:22:38.323706Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = '/kaggle/input/submission-2/submission_2 .tsv'\n",
    "\n",
    "line_count = 0\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        line_count += 1\n",
    "\n",
    "print(\"Number of lines in the file:\", line_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630a5bed",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Answer Note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecc3cf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T03:26:51.241271Z",
     "iopub.status.busy": "2023-08-20T03:26:51.240798Z",
     "iopub.status.idle": "2023-08-20T03:26:57.153858Z",
     "shell.execute_reply": "2023-08-20T03:26:57.152621Z",
     "shell.execute_reply.started": "2023-08-20T03:26:51.241229Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Paths to input TSV files\n",
    "input_file_paths = [\n",
    "    '/kaggle/input/submission-1/submission_1.tsv',\n",
    "    '/kaggle/input/submission-2/submission_2 .tsv'\n",
    "]\n",
    "\n",
    "# Path to the output combined file\n",
    "output_file_path = '/kaggle/working/submission.tsv'\n",
    "\n",
    "# Open the output file in write mode\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    # Loop through each input file\n",
    "    for input_file_path in input_file_paths:\n",
    "        with open(input_file_path, 'r') as input_file:\n",
    "            # Read lines from the input file and write them to the output file\n",
    "            for line in input_file:\n",
    "                output_file.write(line)\n",
    "\n",
    "print(\"Combined TSV files into:\", output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f02105",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 407.856432,
   "end_time": "2023-08-20T04:55:35.930629",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-20T04:48:48.074197",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
