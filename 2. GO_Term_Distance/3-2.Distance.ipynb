{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\n\nUSE_GPU = True\n\nif USE_GPU and torch.cuda.is_available():\n    print('using device: cuda')\nelse:\n    print('using device: cpu')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-20T03:17:37.635092Z","iopub.execute_input":"2023-08-20T03:17:37.635952Z","iopub.status.idle":"2023-08-20T03:17:37.642951Z","shell.execute_reply.started":"2023-08-20T03:17:37.635919Z","shell.execute_reply":"2023-08-20T03:17:37.641126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom Bio import SeqIO\nfrom tqdm import tqdm\nimport torch\nimport pickle\nimport gc","metadata":{"execution":{"iopub.status.busy":"2023-08-21T10:07:46.683651Z","iopub.execute_input":"2023-08-21T10:07:46.684025Z","iopub.status.idle":"2023-08-21T10:07:50.819016Z","shell.execute_reply.started":"2023-08-21T10:07:46.683993Z","shell.execute_reply":"2023-08-21T10:07:50.817947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"markdown","source":"- Train, Test의 단백질 종류 갯수 확인\n- 단백질 하나당 go term의 최대, 최소 갯수\n- 단백질 간 거리 벡터의 용량 확인 (142246 x )","metadata":{}},{"cell_type":"markdown","source":"## Train Data","metadata":{}},{"cell_type":"code","source":"#go-basic.obo\n\nobo_file_path = \"/kaggle/input/cafa-5-protein-function-prediction/Train/go-basic.obo\"\n\nwith open(obo_file_path, \"r\") as obo_file:\n    obo_content = obo_file.read()\n\n# Print the first 1000 characters as an example\nprint(obo_content[:1000])","metadata":{"execution":{"iopub.status.busy":"2023-08-20T04:39:35.439443Z","iopub.execute_input":"2023-08-20T04:39:35.440081Z","iopub.status.idle":"2023-08-20T04:39:35.748793Z","shell.execute_reply.started":"2023-08-20T04:39:35.440048Z","shell.execute_reply":"2023-08-20T04:39:35.747827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_sequence.fast\n\nfasta_file_path = \"/kaggle/input/cafa-5-protein-function-prediction/Train/train_sequences.fasta\"\n\nwith open(fasta_file_path, \"r\") as fasta_file:\n    lines = fasta_file.readlines()\n\nfor line in lines[:10]:  \n    print(line.strip())","metadata":{"execution":{"iopub.status.busy":"2023-08-20T04:39:50.416962Z","iopub.execute_input":"2023-08-20T04:39:50.418675Z","iopub.status.idle":"2023-08-20T04:39:52.227185Z","shell.execute_reply.started":"2023-08-20T04:39:50.418597Z","shell.execute_reply":"2023-08-20T04:39:52.226067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fasta 파일 중 ID, sequence data 불러오기\nfasta_file = '/kaggle/input/cafa-5-protein-function-prediction/Train/train_sequences.fasta'\n\nsequences = []\nfor record in SeqIO.parse(fasta_file, \"fasta\"):\n    sequence_id = record.id\n    sequence_data = record.seq\n    sequences.append((sequence_id, sequence_data))\n\n# sequences[0] : ('P20536', Seq('MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIPDKFFIQLK...FIY'))","metadata":{"execution":{"iopub.status.busy":"2023-08-20T04:40:03.892379Z","iopub.execute_input":"2023-08-20T04:40:03.892756Z","iopub.status.idle":"2023-08-20T04:40:05.746728Z","shell.execute_reply.started":"2023-08-20T04:40:03.892727Z","shell.execute_reply":"2023-08-20T04:40:05.745686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_taxonomy.tsv, train_terms.tsv\ntrain_taxonomy = pd.read_csv(\"/kaggle/input/cafa-5-protein-function-prediction/Train/train_taxonomy.tsv\", sep= \"\\t\")\ntrain_terms = pd.read_csv(\"/kaggle/input/cafa-5-protein-function-prediction/Train/train_terms.tsv\", sep= \"\\t\") \ntrain_terms.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-20T04:40:14.384966Z","iopub.execute_input":"2023-08-20T04:40:14.385313Z","iopub.status.idle":"2023-08-20T04:40:17.104386Z","shell.execute_reply.started":"2023-08-20T04:40:14.385286Z","shell.execute_reply":"2023-08-20T04:40:17.103191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 총 단백질 갯수 및 go term 갯수 확인\nprint(\"Protein #: {}, term #: {}\".format(train_terms['EntryID'].unique().shape, train_terms['term'].unique().shape))","metadata":{"execution":{"iopub.status.busy":"2023-08-20T04:40:29.684651Z","iopub.execute_input":"2023-08-20T04:40:29.685051Z","iopub.status.idle":"2023-08-20T04:40:30.424856Z","shell.execute_reply.started":"2023-08-20T04:40:29.685022Z","shell.execute_reply":"2023-08-20T04:40:30.423436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 하나의 단백질이 갖는 go term의 갯수 확인\ntrain_terms_collected = train_terms.groupby('EntryID')['term'].apply(list).reset_index(name='terms_collected')\nvalue_counts = train_terms_collected['terms_collected'].apply(len)\n\n'''\nvalue_counts = []\nfor i in range(0, len(train_terms_collected)):\n    counts = len(train_terms_collected.loc[i, 'terms_collected'])\n    value_counts.append(counts)\nlen(value_counts)\n'''\ntrain_terms_collected['value_counts'] = train_terms_collected['terms_collected'].apply(len)\nprint(\"value_count min: {}, max: {}\".format(train_terms_collected['value_counts'].min(), train_terms_collected['value_counts'].max()))","metadata":{"execution":{"iopub.status.busy":"2023-08-20T04:40:40.953203Z","iopub.execute_input":"2023-08-20T04:40:40.954374Z","iopub.status.idle":"2023-08-20T04:40:45.459031Z","shell.execute_reply.started":"2023-08-20T04:40:40.954342Z","shell.execute_reply":"2023-08-20T04:40:45.457770Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Embedding vector shape 비교\n\nids_train_ems = np.load(\"/kaggle/input/cafa-5-ems-2-embeddings-numpy/train_ids.npy\")\nembeds_ems_train = np.load(\"/kaggle/input/cafa-5-ems-2-embeddings-numpy/train_embeddings.npy\")\nprint(\"ems       ids# : {}, embedding_dim : {}\".format(len(ids_train_ems), embeds_ems_train.shape))\n\nids_train_protbert = np.load(\"/kaggle/input/protbert-embeddings-for-cafa5/train_ids.npy\")\nembeds_protbert_train = np.load(\"/kaggle/input/protbert-embeddings-for-cafa5/train_embeddings.npy\")\nprint(\"protbert  ids# : {}, embedding_dim : {}\".format(len(ids_train_protbert), embeds_protbert_train.shape))","metadata":{"execution":{"iopub.status.busy":"2023-08-20T04:40:59.889824Z","iopub.execute_input":"2023-08-20T04:40:59.890212Z","iopub.status.idle":"2023-08-20T04:41:13.650219Z","shell.execute_reply.started":"2023-08-20T04:40:59.890184Z","shell.execute_reply":"2023-08-20T04:41:13.649161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 메모리 확인 \nimport numpy as np\n\n# Create a numpy array\ndata = embeds_ems_train\n\n# Calculate the memory capacity consumed by the array\nmemory_consumed_bytes = data.nbytes\n\n# Convert bytes to more human-readable format\ndef format_bytes(size):\n    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:\n        if size < 1024.0:\n            return f\"{size:.2f} {unit}\"\n        size /= 1024.0\n    return f\"{size:.2f} PB\"\n\nmemory_consumed_human_readable = format_bytes(memory_consumed_bytes)\n\nprint(\"Memory consumed by array:\", memory_consumed_human_readable)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-20T04:41:13.652213Z","iopub.execute_input":"2023-08-20T04:41:13.652854Z","iopub.status.idle":"2023-08-20T04:41:13.660523Z","shell.execute_reply.started":"2023-08-20T04:41:13.652817Z","shell.execute_reply":"2023-08-20T04:41:13.659528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test Data","metadata":{}},{"cell_type":"code","source":"# testsuperset-taxon-list.tsv\ntest_taxonomy = pd.read_csv(\"/kaggle/input/cafa-5-protein-function-prediction/Test (Targets)/testsuperset-taxon-list.tsv\", sep=\"\\t\", encoding=\"ISO-8859-1\")","metadata":{"execution":{"iopub.status.busy":"2023-08-20T04:41:36.608958Z","iopub.execute_input":"2023-08-20T04:41:36.609298Z","iopub.status.idle":"2023-08-20T04:41:36.624011Z","shell.execute_reply.started":"2023-08-20T04:41:36.609272Z","shell.execute_reply":"2023-08-20T04:41:36.622406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# testsuperset.fasta\nfasta_file_path = \"/kaggle/input/cafa-5-protein-function-prediction/Test (Targets)/testsuperset.fasta\"\n\nwith open(fasta_file_path, \"r\") as fasta_file:\n    lines = fasta_file.readlines()\n\nfor line in lines[:10]:\n    print(line.strip())","metadata":{"execution":{"iopub.status.busy":"2023-08-20T04:41:44.329239Z","iopub.execute_input":"2023-08-20T04:41:44.329599Z","iopub.status.idle":"2023-08-20T04:41:45.806880Z","shell.execute_reply.started":"2023-08-20T04:41:44.329571Z","shell.execute_reply":"2023-08-20T04:41:45.805486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fasta 파일 중 ID, sequence data 불러오기\nfasta_file = '/kaggle/input/cafa-5-protein-function-prediction/Test (Targets)/testsuperset.fasta'\n\nsequences = []\nfor record in SeqIO.parse(fasta_file, \"fasta\"):\n    sequence_id = record.id\n    sequence_data = record.seq\n    sequences.append((sequence_id, sequence_data))\n\n# sequences[0] : ('P20536', Seq('MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIPDKFFIQLK...FIY'))\n\n'''\nlen(sequences) 141865 인데, dictionary form으로 전환하면  141864가 나옴. \n중복 데이터가 있다고 판단하여 아래 코드를 수행해봄\n* 중복 데이터는 다른 사람이 만들어 놓은 embedding vector 갯수가 141854라 알게되었음.\n'''","metadata":{"execution":{"iopub.status.busy":"2023-08-20T04:41:56.494835Z","iopub.execute_input":"2023-08-20T04:41:56.495198Z","iopub.status.idle":"2023-08-20T04:41:58.464181Z","shell.execute_reply.started":"2023-08-20T04:41:56.495173Z","shell.execute_reply":"2023-08-20T04:41:58.462867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 중복 데이터 확인 \nfrom tqdm import tqdm\n\nx = [] # 처음 등장한 값인지 판별하는 리스트\nnew_a = [] # 중복된 원소만 넣는 리스트\n\nfor i in tqdm(sequences):\n    if i not in x: \n        x.append(i)\n    else:\n        if i not in new_a: # 이미 중복 원소로 판정된 경우는 제외\n            new_a.append(i)\n\nprint(new_a) # [1, 2] # 2회 이상 등장한 값들만 담긴 리스트\n# 중복 데이터: [('A0A1D6E0S8', Seq('MPSRSPACRPRGRNRRSAADAVARPLALALILVSTLPRAAHSQDLALPPVQPRG...SFC'))]","metadata":{"execution":{"iopub.status.busy":"2023-08-20T04:42:05.172820Z","iopub.execute_input":"2023-08-20T04:42:05.173196Z","iopub.status.idle":"2023-08-20T04:47:53.954266Z","shell.execute_reply.started":"2023-08-20T04:42:05.173172Z","shell.execute_reply":"2023-08-20T04:47:53.952938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Go term 예측: 1과 2 방법을 혼합하여 예측한다.\n- Vector distance가 가까운 단백질은 같은 go term을 공유한다고 간주하고, 나머지는 Newural network system으로 예측한다.\n- 가까운 vector distance의 명확한 기준은 없으므로 이용자가 임의로 정한다.\n\n1. Sequence vector distances.\n2. Neural Network","metadata":{}},{"cell_type":"markdown","source":"# 1. Sequence vector distances.\n- 단백질 sequence vector간 거리가 가까울 수록 비슷한 단백질.\n- 비슷한 단백질을 하는 역할이 비슷함.\n- 단백질 간 거리가 가까우면 비슷한 go term을 공유한다.\n- 참조 문헌: https ://github.com/Rostl ab/goPre dSim","metadata":{}},{"cell_type":"code","source":"# Train x Test (142246 * 141864) tensor 용량 계산\nimport torch\n\n# Define the tensor shape and data type\ntensor_shape = (142246, 141864)\ndata_type = torch.float32\n\n# Create a tensor of the specified shape and data type\ntensor = torch.empty(tensor_shape, dtype=data_type)\n\n# Calculate the memory consumption in bytes\nmemory_bytes = tensor.element_size() * tensor.numel()\n\n# Convert bytes to gigabytes\nmemory_gb = memory_bytes / (1024 ** 3)\n\nprint(\"Memory Consumption of the Tensor: {:.2f} GB\".format(memory_gb))\n\n# Memory Consumption of the Tensor: 75.17 GB","metadata":{"execution":{"iopub.status.busy":"2023-08-20T04:48:16.672162Z","iopub.execute_input":"2023-08-20T04:48:16.672543Z","iopub.status.idle":"2023-08-20T04:48:16.690956Z","shell.execute_reply.started":"2023-08-20T04:48:16.672512Z","shell.execute_reply":"2023-08-20T04:48:16.689769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pickle 파일 만들기\n- Output 용량의 한계로 0 - 15k 까지만 만들었음.","metadata":{}},{"cell_type":"code","source":"# Data load\nids_train = np.load(\"/kaggle/input/protbert-embeddings-for-cafa5/train_ids.npy\")\nembeds_protbert_train = np.load(\"/kaggle/input/protbert-embeddings-for-cafa5/train_embeddings.npy\")\n\n# Protein Id, embedding vectors dictionary\ndict_train_id_embeds = {}\nfor i in zip(ids_train, embeds_protbert_train):\n    dict_train_id_embeds[i[0]] = i[1]\nprint(type(dict_train_id_embeds), len(dict_train_id_embeds))","metadata":{"execution":{"iopub.status.busy":"2023-08-17T07:30:37.976062Z","iopub.execute_input":"2023-08-17T07:30:37.976795Z","iopub.status.idle":"2023-08-17T07:30:45.357435Z","shell.execute_reply.started":"2023-08-17T07:30:37.976756Z","shell.execute_reply":"2023-08-17T07:30:45.356418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# portbert embedding의 경우 141865개가 있다.\n# len(ids_test)와 dictionary의 key값이 달라 확인해봄*\n# 이는 중복된 ID가 있기 때문인데 실제 대회측에서 준 test ID 갯수도 141864개이다.\n# Data load\nids_test = np.load(\"/kaggle/input/protbert-embeddings-for-cafa5/test_ids.npy\")\nembeds_protbert_test = np.load(\"/kaggle/input/protbert-embeddings-for-cafa5/test_embeddings.npy\")\n\n# Protein Id, embedding vectors dictionary\ndict_test_id_embeds = {}\nfor i in zip(ids_test, embeds_protbert_test):\n    dict_test_id_embeds[i[0]] = i[1]\nprint(type(dict_test_id_embeds), len(dict_test_id_embeds))","metadata":{"execution":{"iopub.status.busy":"2023-08-17T07:30:45.361473Z","iopub.execute_input":"2023-08-17T07:30:45.361797Z","iopub.status.idle":"2023-08-17T07:30:50.642271Z","shell.execute_reply.started":"2023-08-17T07:30:45.361771Z","shell.execute_reply":"2023-08-17T07:30:50.641272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport gc\n\n# Convert dictionary values to NumPy arrays\nraw_data = np.array(list(dict_train_id_embeds.values()))\nraw_data_query = np.array(list(dict_test_id_embeds.values()))\n\n# Convert NumPy arrays to tensors\nimport torch\n\ntensor_raw_data = torch.tensor(raw_data).to('cuda')\ntensor_raw_data_query = torch.tensor(raw_data_query).to('cuda')\n\n# GPU 위에 올렸으므로 ram위에 올라간 raw_data, raw_data_query를 지운다.\ndel raw_data\ndel raw_data_query\ndel dict_train_id_embeds\ndel ids_train\ndel embeds_protbert_train\ndel dict_test_id_embeds\ndel ids_test\ndel embeds_protbert_test\ngc_collect = gc.collect()\n\nprint(torch.cuda.is_available(), tensor_raw_data.is_cuda, tensor_raw_data_query.is_cuda)\nprint(tensor_raw_data.shape, tensor_raw_data_query.shape)\nprint(gc_collect)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T07:30:50.643792Z","iopub.execute_input":"2023-08-17T07:30:50.644352Z","iopub.status.idle":"2023-08-17T07:30:55.584455Z","shell.execute_reply.started":"2023-08-17T07:30:50.644318Z","shell.execute_reply":"2023-08-17T07:30:55.583436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from Bio import SeqIO\n\nfile_path = \"/kaggle/input/cafa-5-protein-function-prediction/Test (Targets)/testsuperset.fasta\"\n\n# Open the FASTA file and iterate through its records\nwith open(file_path, \"r\") as fasta_file:\n    records = SeqIO.parse(fasta_file, \"fasta\")\n    \n    id_set = set()\n    for record in records:\n        # Add the record ID to the set\n        id_set.add(record.id)\n\n# Print the number of unique IDs\nnum_ids = len(id_set)\nprint(\"Number of unique IDs:\", num_ids)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T07:30:55.585948Z","iopub.execute_input":"2023-08-17T07:30:55.586567Z","iopub.status.idle":"2023-08-17T07:30:57.890192Z","shell.execute_reply.started":"2023-08-17T07:30:55.586533Z","shell.execute_reply":"2023-08-17T07:30:57.889127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport subprocess\nfrom IPython.display import FileLink, display\n\ndef download_file(path, download_file_name):\n    os.chdir('/kaggle/working/')\n    zip_name = f\"/kaggle/working/{download_file_name}.zip\"\n    command = f\"zip {zip_name} {path} -r\"\n    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n    if result.returncode != 0:\n        print(\"Unable to run zip command!\")\n        print(result.stderr)\n        return\n    display(FileLink(f'{download_file_name}.zip'))","metadata":{"execution":{"iopub.status.busy":"2023-08-19T17:17:10.656275Z","iopub.execute_input":"2023-08-19T17:17:10.656744Z","iopub.status.idle":"2023-08-19T17:17:10.667599Z","shell.execute_reply.started":"2023-08-19T17:17:10.656709Z","shell.execute_reply":"2023-08-19T17:17:10.666028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    batch_size_d = 5000\n    \n    pbar = tqdm(range(0, 20000, batch_size_d)) #len(tensor_raw_data)\n    \n    for i in pbar: #140000 , len(tensor_raw_data) : 142246\n        batch_data = tensor_raw_data[i:i+batch_size_d]\n        query_tensor = torch.cdist(batch_data, tensor_raw_data_query, p=2).cpu()\n        \n        distance_tensor_name = f'distance_tensor_{i}.pkl'\n        \n        with open(distance_tensor_name, 'wb') as f:\n            pickle.dump(query_tensor, f)\n        \n        print(distance_tensor_name)\n        \n        del query_tensor\n        del distance_tensor_name\n        torch.cuda.empty_cache()\n        collected = gc.collect()\n        print(f\"Garbage collector: collected {collected} objects\")","metadata":{"execution":{"iopub.status.busy":"2023-08-17T07:30:57.912473Z","iopub.execute_input":"2023-08-17T07:30:57.912787Z","iopub.status.idle":"2023-08-17T07:32:04.259543Z","shell.execute_reply.started":"2023-08-17T07:30:57.912761Z","shell.execute_reply":"2023-08-17T07:32:04.258479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi\ntorch.cuda.memory_allocated(), torch.cuda.max_memory_allocated()","metadata":{"execution":{"iopub.status.busy":"2023-08-17T07:32:04.261108Z","iopub.execute_input":"2023-08-17T07:32:04.261540Z","iopub.status.idle":"2023-08-17T07:32:05.433078Z","shell.execute_reply.started":"2023-08-17T07:32:04.261508Z","shell.execute_reply":"2023-08-17T07:32:05.431890Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"download_file('/kaggle/working/distance_tensor_15000.pkl', 'distance_tensor_15000')","metadata":{"execution":{"iopub.status.busy":"2023-08-17T08:02:19.679153Z","iopub.execute_input":"2023-08-17T08:02:19.680220Z","iopub.status.idle":"2023-08-17T08:05:17.300201Z","shell.execute_reply.started":"2023-08-17T08:02:19.680181Z","shell.execute_reply":"2023-08-17T08:05:17.299028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#del download_file('/kaggle/working/distance_tensor_0.pkl', 'distance_tensor_0')\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-08-17T07:42:05.199213Z","iopub.execute_input":"2023-08-17T07:42:05.200359Z","iopub.status.idle":"2023-08-17T07:42:05.409445Z","shell.execute_reply.started":"2023-08-17T07:42:05.200320Z","shell.execute_reply":"2023-08-17T07:42:05.408257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"''' \ndownload_file('/kaggle/working/distance_tensor_0.pkl', 'distance_tensor_0')\ndownload_file('/kaggle/working/distance_tensor_5000.pkl', 'distance_tensor_5000')\ndownload_file('/kaggle/working/distance_tensor_10000.pkl', 'distance_tensor_10000')\ndownload_file('/kaggle/working/distance_tensor_15000.pkl', 'distance_tensor_15000')\ndownload_file('/kaggle/working/distance_tensor_20000.pkl', 'distance_tensor_20000')\ndownload_file('/kaggle/working/distance_tensor_25000.pkl', 'distance_tensor_25000')\ndownload_file('/kaggle/working/distance_tensor_30000.pkl', 'distance_tensor_30000')\ndownload_file('/kaggle/working/distance_tensor_35000.pkl', 'distance_tensor_35000')\n\n'''\n","metadata":{"execution":{"iopub.status.busy":"2023-08-17T07:32:07.444217Z","iopub.execute_input":"2023-08-17T07:32:07.444654Z","iopub.status.idle":"2023-08-17T07:32:07.454744Z","shell.execute_reply.started":"2023-08-17T07:32:07.444620Z","shell.execute_reply":"2023-08-17T07:32:07.453527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pickle_file_path = '/kaggle/working/distance_tensor_0.pkl'\n\n# Load the pickle file\nwith open(pickle_file_path, 'rb') as f:\n    loaded_data = pickle.load(f)\n\n# Now you can use the loaded_data as needed\nprint(loaded_data, loaded_data.shape)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T07:32:07.456334Z","iopub.execute_input":"2023-08-17T07:32:07.456953Z","iopub.status.idle":"2023-08-17T07:32:26.964154Z","shell.execute_reply.started":"2023-08-17T07:32:07.456920Z","shell.execute_reply":"2023-08-17T07:32:26.962684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pickle 파일 연결","metadata":{}},{"cell_type":"code","source":"import pickle\n\n'''\nfile_path_1 = '/kaggle/input/distance-tensor-0to20k/distance_tensor_0.pkl'\nwith open(file_path_1, 'rb') as file:\n    distance_tensor_0 = pickle.load(file)\n\nfile_path_2 = '/kaggle/input/distance-tensor-0to20k/distance_tensor_5000.pkl'\nwith open(file_path_2, 'rb') as file:\n    distance_tensor_5000 = pickle.load(file)\n        \nfile_path_1 = '/kaggle/input/distance-tensor-0to20k/distance_tensor_15000.pkl'\nwith open(file_path_1, 'rb') as file:\n    distance_tensor_15000 = pickle.load(file) \n'''\n\nfile_path_1 = '/kaggle/input/distance-tensor-0to20k/distance_tensor_10000.pkl'\nwith open(file_path_1, 'rb') as file:\n    distance_tensor_10000 = pickle.load(file)\n\n   \n#print(distance_tensor_0.shape, distance_tensor_5000.shape)\nprint(distance_tensor_10000.shape)\n#print(distance_tensor_15000.shape)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T12:37:25.697037Z","iopub.execute_input":"2023-08-17T12:37:25.697507Z","iopub.status.idle":"2023-08-17T12:37:50.077283Z","shell.execute_reply.started":"2023-08-17T12:37:25.697472Z","shell.execute_reply":"2023-08-17T12:37:50.075741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#distance_tensor_0to10k = torch.cat((distance_tensor_0, distance_tensor_5000), dim=0)\ndistance_tensor_0to15k = torch.cat((distance_tensor_0to10k, distance_tensor_10000), dim=0)\n#distance_tensor_0to20k = torch.cat((distance_tensor_0to15k, distance_tensor_15000), dim=0)\n\n#print(distance_tensor_0to10k.shape)\nprint(distance_tensor_0to15k.shape)\n#print(distance_tensor_0to20k.shape)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T12:38:38.214698Z","iopub.execute_input":"2023-08-17T12:38:38.215258Z","iopub.status.idle":"2023-08-17T12:38:42.174465Z","shell.execute_reply.started":"2023-08-17T12:38:38.215217Z","shell.execute_reply":"2023-08-17T12:38:42.172910Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#del distance_tensor_5000\n#gc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-08-19T05:02:24.758509Z","iopub.execute_input":"2023-08-19T05:02:24.758907Z","iopub.status.idle":"2023-08-19T05:02:24.764441Z","shell.execute_reply.started":"2023-08-19T05:02:24.758876Z","shell.execute_reply":"2023-08-19T05:02:24.763229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_path = 'distance_tensor_0to15k.pkl'\n\n# Save the data to a pickle file\nwith open(file_path, 'wb') as f:\n    pickle.dump(distance_tensor_0to15k, f)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T12:41:27.790248Z","iopub.execute_input":"2023-08-17T12:41:27.790745Z","iopub.status.idle":"2023-08-17T12:42:06.644954Z","shell.execute_reply.started":"2023-08-17T12:41:27.790704Z","shell.execute_reply":"2023-08-17T12:42:06.643710Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"download_file('/kaggle/working/distance_tensor_0to15k.pkl', 'distance_tensor_0to15k.pkl')","metadata":{"execution":{"iopub.status.busy":"2023-08-17T12:43:01.158374Z","iopub.execute_input":"2023-08-17T12:43:01.158812Z","iopub.status.idle":"2023-08-17T12:53:16.371081Z","shell.execute_reply.started":"2023-08-17T12:43:01.158778Z","shell.execute_reply":"2023-08-17T12:53:16.370137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r file.zip /kaggle/working/distance_tensor_0to20k.pkl","metadata":{"execution":{"iopub.status.busy":"2023-08-17T12:14:55.460145Z","iopub.execute_input":"2023-08-17T12:14:55.460707Z","iopub.status.idle":"2023-08-17T12:28:03.021953Z","shell.execute_reply.started":"2023-08-17T12:14:55.460660Z","shell.execute_reply":"2023-08-17T12:28:03.020023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tensor 자르고 붙이는 연습\n'''\n#garbage collector가 gpu에서 삭제\n#no grad 적용/ # tensor_raw_data_query 쪼개서 이중 for문으로 만들기\n#garbage collector가 gpu에서 삭제\n\nwith torch.no_grad():\n    result_tensor_1 = []\n    \n    batch_size_d = 100\n    batch_size_q = 100\n    \n    pbar = tqdm(range (5000,10000, batch_size_d))\n    for i in pbar:\n        batch_data = tensor_raw_data[i:i+batch_size_d]\n        query_tensor = [] # query_tensor는 비워줘야 한다.\n        \n        for j in range(0,len(tensor_raw_data_query), batch_size_q):\n            batch_query = tensor_raw_data_query[j:j+batch_size_q]\n            distance_query_seg = torch.cdist(batch_data, batch_query, p=2)\n            query_tensor.append(distance_query_seg)\n            \n        distance_data_seg = torch.cat(query_tensor, dim=1)#.cpu()\n        result_tensor_1.append(distance_data_seg)\n        \n    pbar.close()\n    distance_tensor_2 = torch.cat(result_tensor_1, dim=0)#.cpu()\n    #print(\"distance_tensor_1:\", distance_tensor_1)\n\nwith open('distance_tensor_2.pkl', 'wb') as f:\n\tpickle.dump(distance_tensor_2, f)\n'''\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Embedding vector 거리 구하기\n- goPreSim에서 구한 방식으로는 computing 능력이 부족하여 할 수 가 없음.\n- 따라서, torch에서 batch로 나누어 약 14만 개중 2만개의 train protein vector와 약 14만개의 test vector간의 거리를 구함","metadata":{}},{"cell_type":"code","source":"# Distance vector loading\nfile_path = '/kaggle/input/distance-tensor-con-0to15k/distance_tensor_0to15k.pkl'\n\nwith open(file_path, 'rb') as file:\n    distance_tensor_0to15k = pickle.load(file)\nprint(distance_tensor_0to15k.shape, distance_tensor_0to15k.min(), distance_tensor_0to15k.max())","metadata":{"execution":{"iopub.status.busy":"2023-08-20T01:16:12.250375Z","iopub.execute_input":"2023-08-20T01:16:12.250874Z","iopub.status.idle":"2023-08-20T01:18:13.186926Z","shell.execute_reply.started":"2023-08-20T01:16:12.250830Z","shell.execute_reply":"2023-08-20T01:18:13.185268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test data의 단백질 id loading\nids_test = np.load(\"/kaggle/input/protbert-embeddings-for-cafa5/test_ids.npy\")\nids_test_dict = {}\nfor id_test in ids_test:\n    ids_test_dict[id_test] = 0\nlen(ids_test_dict)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T01:18:13.189613Z","iopub.execute_input":"2023-08-20T01:18:13.190056Z","iopub.status.idle":"2023-08-20T01:18:13.387120Z","shell.execute_reply.started":"2023-08-20T01:18:13.189995Z","shell.execute_reply":"2023-08-20T01:18:13.385949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# index로 단백질 id를 찾을 수 있게 해주는 사전\nids_train = np.load(\"/kaggle/input/protbert-embeddings-for-cafa5/train_ids.npy\")\nids_train_list = ids_train[:15000]\nids_train_numbering = {}\nfor i in range(0,len(ids_train_list)):\n    ids_train_numbering[i] = ids_train[i]","metadata":{"execution":{"iopub.status.busy":"2023-08-20T01:18:13.388479Z","iopub.execute_input":"2023-08-20T01:18:13.389606Z","iopub.status.idle":"2023-08-20T01:18:13.498355Z","shell.execute_reply.started":"2023-08-20T01:18:13.389563Z","shell.execute_reply":"2023-08-20T01:18:13.497205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Distance vector loading\nfile_path = '/kaggle/input/dict-train-id-goterm/dict_train_id_go_term'\n\nwith open(file_path, 'rb') as file:\n    dict_train_id_go_term = pickle.load(file)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T01:18:13.501516Z","iopub.execute_input":"2023-08-20T01:18:13.501973Z","iopub.status.idle":"2023-08-20T01:18:14.577831Z","shell.execute_reply.started":"2023-08-20T01:18:13.501931Z","shell.execute_reply":"2023-08-20T01:18:14.576721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# goPredSim Data: \n!git clone https://github.com/Rostlab/goPredSim","metadata":{"execution":{"iopub.status.busy":"2023-08-20T01:18:14.579446Z","iopub.execute_input":"2023-08-20T01:18:14.579890Z","iopub.status.idle":"2023-08-20T01:18:23.566744Z","shell.execute_reply.started":"2023-08-20T01:18:14.579848Z","shell.execute_reply":"2023-08-20T01:18:23.565395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# goPredSim에서 만든 코드를 이용해 parents go term을 불러오기 위한 함수 loading\nimport sys\nsys.path.append('/kaggle/working/goPredSim')\nfrom gene_ontology import GeneOntology\n\nonto_file = \"/kaggle/input/cafa-5-protein-function-prediction/Train/go-basic.obo\"\ngo = GeneOntology(onto_file)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T01:18:23.569385Z","iopub.execute_input":"2023-08-20T01:18:23.569845Z","iopub.status.idle":"2023-08-20T01:19:06.746323Z","shell.execute_reply.started":"2023-08-20T01:18:23.569795Z","shell.execute_reply":"2023-08-20T01:19:06.745051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 현재 문제점: 연산이 너무 느림 -> gpu 연산으로 해결하는 방법이 있을 것 같다.\n# ### dist에 들어갈 tensor를 변경 'dists = distance_tensor_0to15k[:,i].tolist()'\n\nfrom collections import defaultdict\nfrom tqdm import tqdm\n\npredictions = defaultdict(defaultdict)\nhit_ids = defaultdict(defaultdict)\nhits = [0.7] \n\nfor i in tqdm(range(80000, len(ids_test_dict))): #(0:80000), (80000,len(ids_test_dict))\n    query = ids_test[i].split()[0] #ids_test[i] 이렇게만 해도 되나 일단 원본을 최대한 유지\n    dists = distance_tensor_0to15k[:,i].tolist()  \n    dists = np.array(dists)\n    \n    for h in hits:\n        prediction = dict() #line by line으로 만들 때는 prediction = dict(hits)에러가 난다.\n        \n        h = float(h)\n        indices = np.nonzero(dists <= h)[0] #[0]이 없으면 array(,형태로나옴)\n\n        '''\n        h = int(h)\n        indices_tmp = np.argpartition(dists, h)[0:h]\n        dists_tmp = [dists[i] for i in indices_tmp]\n        max_dist = np.amax(dists_tmp)\n        indices = np.nonzero(dists <= max_dist)[0]\n\n        '''\n                \n        num_hits = len(indices)\n        \n        for ind in indices:\n            lookup_id = ids_train_numbering[ind]        #self.lookup_db.ids[ind]  # ids_train_numbering\n            go_terms = dict_train_id_go_term[lookup_id]\n            dist = dists[ind]                                #self.go_db[lookup_id]\n            dist = 0.5 / (0.5 + dist)\n            \n            for g in go_terms:\n                if g in prediction.keys():\n                    prediction[g] += dist/num_hits\n                else:\n                    prediction[g] = dist/num_hits\n            \n            if query not in hit_ids[h].keys():\n        \n                hit_ids[h][query] = dict() #  h 값과 query 값으로 중첩된 딕셔너리 구조가 생성\n                hit_ids[h][query][lookup_id] = round(dist, 2) # 소수 둘째 자리 까지 반올림 하여 저장!\n\n         # 낮은 확률 삭제\n        keys_for_deletion = set()\n        for p in prediction:\n            ri = round(float(prediction[p]), 2) # 은 현재 키에 해당하는 값을 반올림하여 ri 변수에 할당\n            if ri == 0.00:\n                keys_for_deletion.add(p)\n            else:\n                prediction[p] = ri\n\n        for k in keys_for_deletion:\n            del prediction[k]\n\n        # 부모 go term을 삭제 하는 이유: 더 정확한 예측을 위해서 삭제한다.!\n        parent_terms = []\n        for p in prediction.keys():\n            parents = go.get_parent_terms(p) # 이 함수는 가지고 와야함\n            parent_terms += parents\n\n        keys_for_deletion = set()\n        for p in prediction.keys():\n            if p in parent_terms:\n                keys_for_deletion.add(p)\n\n        for k in keys_for_deletion:\n            del prediction[k]\n\n        predictions[h][query] = prediction \n\ntqdm.close\n\nprint(predictions, hit_ids)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T01:19:16.251268Z","iopub.execute_input":"2023-08-20T01:19:16.252421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"7만개 = 10 기가 2 시간 50%","metadata":{}},{"cell_type":"code","source":"out_file = \"/kaggle/working/submission_2 .tsv\"  # Change extension to .tsv\n\ntry:\n    with open(out_file, 'w') as out:\n        for p in predictions.keys():\n            prediction = predictions[p]\n            for protein_ID in prediction.keys():  # prediction.keys() == protein_IDs \n                go_terms_ri = prediction[protein_ID]\n                for go_term in go_terms_ri.keys():\n                    ri = go_terms_ri[go_term]\n                    out.write('{}\\t{}\\t'.format(protein_ID, go_term))  # protein_ID, go_term\n                    out.write('{:0.2f}\\n'.format(float(ri)))  # ri probability\n    print(f\"Data written to '{out_file}' successfully.\")\nexcept Exception as e:\n    print(\"An error occurred:\", e)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T03:09:52.083862Z","iopub.execute_input":"2023-08-20T03:09:52.085169Z","iopub.status.idle":"2023-08-20T03:10:16.744834Z","shell.execute_reply.started":"2023-08-20T03:09:52.085120Z","shell.execute_reply":"2023-08-20T03:10:16.743717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_path = '/kaggle/input/submission-2/submission_2 .tsv'\n\nline_count = 0\n\nwith open(file_path, 'r') as file:\n    for line in file:\n        line_count += 1\n\nprint(\"Number of lines in the file:\", line_count)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T03:22:38.322817Z","iopub.execute_input":"2023-08-20T03:22:38.323762Z","iopub.status.idle":"2023-08-20T03:22:41.492181Z","shell.execute_reply.started":"2023-08-20T03:22:38.323706Z","shell.execute_reply":"2023-08-20T03:22:41.490763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Sequence vector 거리 기준 TSV 파일","metadata":{}},{"cell_type":"code","source":"# Sequence vector간 거리 기준으로 정답 예측\n\ninput_file_paths = [\n    '/kaggle/input/submission-1/submission_1.tsv',\n    '/kaggle/input/submission-2/submission_2 .tsv'\n]\n\noutput_file_path = '/kaggle/working/submission.tsv'\n\nwith open(output_file_path, 'w') as output_file:\n    for input_file_path in input_file_paths:\n        with open(input_file_path, 'r') as input_file:\n            for line in input_file:\n                output_file.write(line)\n\nprint(\"Combined TSV files into:\", output_file_path)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T10:08:08.368226Z","iopub.execute_input":"2023-08-21T10:08:08.369082Z","iopub.status.idle":"2023-08-21T10:08:18.012598Z","shell.execute_reply.started":"2023-08-21T10:08:08.369043Z","shell.execute_reply":"2023-08-21T10:08:18.011385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TSV 파일을 pandas dataframe으로 변경\nfile_path = '/kaggle/input/combined-submission/submission.tsv'\nvector_distance_df = pd.read_csv(file_path, sep='\\t')\n\n# Set the column names\ncolumn_names = ['Protein Id', 'GO Term Id', 'Prediction']\nvector_distance_df.columns = column_names\nprint(vector_distance_df['Protein Id'].nunique(), len(vector_distance_df))\n'''\nTest protein ID 갯수가 141864임을 감안하면 약 3만개 정도는 거리가 0.01 미만으로 go term이 예측\n되지 않았음을 알 수 있다.\n'''","metadata":{"execution":{"iopub.status.busy":"2023-08-21T10:08:18.014731Z","iopub.execute_input":"2023-08-21T10:08:18.015283Z","iopub.status.idle":"2023-08-21T10:08:34.225670Z","shell.execute_reply.started":"2023-08-21T10:08:18.015242Z","shell.execute_reply":"2023-08-21T10:08:34.224575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 특정 확률 이상만 추출\nselected_vd_df = vector_distance_df[vector_distance_df['Prediction'] > 0.8]\n# Print the selected rows\nprint(selected_vd_df['Protein Id'].nunique(), len(selected_vd_df))","metadata":{"execution":{"iopub.status.busy":"2023-08-21T10:09:34.546014Z","iopub.execute_input":"2023-08-21T10:09:34.547089Z","iopub.status.idle":"2023-08-21T10:09:34.581345Z","shell.execute_reply.started":"2023-08-21T10:09:34.547051Z","shell.execute_reply":"2023-08-21T10:09:34.580586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Neural Network\n- 같은 팀원의 코드를 참고하여 작성함 (@ YIMINJAE98)\n- Tensorflow 기반으로 작성 하였음.\n- 1번과 2번을 독립적으로 활용 할 수 있도록 data load 부터 예측까지 모든 코드를 넣음.","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pickle\nimport tensorflow as tf\nfrom tensorflow import keras\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport progressbar\nimport gc","metadata":{"execution":{"iopub.status.busy":"2023-08-21T10:04:11.539578Z","iopub.execute_input":"2023-08-21T10:04:11.540042Z","iopub.status.idle":"2023-08-21T10:04:20.739871Z","shell.execute_reply.started":"2023-08-21T10:04:11.540005Z","shell.execute_reply":"2023-08-21T10:04:20.738823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data 불러오기","metadata":{}},{"cell_type":"code","source":"#Load Data \ntrain_terms = pd.read_csv('/kaggle/input/cafa-5-protein-function-prediction/Train/train_terms.tsv',sep='\\t')\ntrain_embeddings = np.load('/kaggle/input/t5embeds/train_embeds.npy')\ntrain_id = np.load('/kaggle/input/t5embeds/train_ids.npy')\nprint(train_id.shape,train_embeddings.shape)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T10:04:30.872628Z","iopub.execute_input":"2023-08-21T10:04:30.873261Z","iopub.status.idle":"2023-08-21T10:04:44.644985Z","shell.execute_reply.started":"2023-08-21T10:04:30.873228Z","shell.execute_reply":"2023-08-21T10:04:44.644198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pandas dataframe으로 변환\ncolumn_num = train_embeddings.shape[1] # embedding vector한 개 당 차원 (1,1024)\ntrain_df = pd.DataFrame(train_embeddings, columns = [\"Column_\" + str(i) for i in range(1, column_num+1)])\ntrain_df['ID'] = train_id","metadata":{"execution":{"iopub.status.busy":"2023-08-21T09:46:39.979563Z","iopub.execute_input":"2023-08-21T09:46:39.979879Z","iopub.status.idle":"2023-08-21T09:46:40.002529Z","shell.execute_reply.started":"2023-08-21T09:46:39.979851Z","shell.execute_reply":"2023-08-21T09:46:40.000856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ngo term 정답레이블을 0 ,1 형태의 행렬로 나타내는 코드.\ngo term label이 1500개인 이유는 정답 제출시 하나의 단백질당 예측가능한 최대 go-term 숫자가 1500개로 제한\n(실제로 가장 자주 사용되는 go term 1500 개를 활요하면 더 유용할 것같다고 생각이 드나, \n대회 일정상 임의로 1500 개를 자름)\n'''\n\n'''\n# Set the limit for label\nnum_of_labels = 1500\ntrain_size = train_id.shape[0] # len(X)\n\n# Take value counts in descending order and fetch first 1500 `GO term ID` as labels\nlabels = train_terms['term'].value_counts().index[:num_of_labels].tolist()\n\n# Fetch the train_terms data for the relevant labels only\ntrain_terms_updated = train_terms.loc[train_terms['term'].isin(labels)]\n\n# Setup progressbar settings.\nbar = progressbar.ProgressBar(maxval=num_of_labels, \\\n    widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n\n# Create an empty dataframe of required size for storing the labels,\ntrain_labels = np.zeros((train_size ,num_of_labels))\nseries_train_protein_ids = pd.Series(train_id)\n\n# Loop through each label\nfor i in range(num_of_labels):\n    # For each label, fetch the corresponding train_terms data\n    n_train_terms = train_terms_updated[train_terms_updated['term'] ==  labels[i]]\n    \n    # Fetch all the unique EntryId aka proteins related to the current label(GO term ID)\n    label_related_proteins = n_train_terms['EntryID'].unique()\n    \n    # In the series_train_protein_ids pandas series, if a protein is related\n    # to the current label, then mark it as 1, else 0.\n    # Replace the ith column of train_Y with with that pandas series.\n    train_labels[:,i] =  series_train_protein_ids.isin(label_related_proteins).astype(float)\n    \n    # Progress bar percentage increase\n    bar.update(i+1)\n\n# Notify the end of progress bar \nbar.finish()\n\n# Convert train_Y numpy into pandas dataframe\nlabels_df = pd.DataFrame(data = train_labels, columns = labels)\nprint(labels_df.shape)\n'''","metadata":{"execution":{"iopub.status.busy":"2023-08-21T09:48:22.387911Z","iopub.execute_input":"2023-08-21T09:48:22.388275Z","iopub.status.idle":"2023-08-21T09:48:22.395799Z","shell.execute_reply.started":"2023-08-21T09:48:22.388247Z","shell.execute_reply":"2023-08-21T09:48:22.394797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# labels_df pickle 파일 loading, \nfile_path = \"/kaggle/input/labels-df/labels_df_ver1.pkl\"\n\nwith open(file_path, 'rb') as file:\n    labels_df = pickle.load(file)\n\n\nfeatures_input = train_df.loc[:, train_df.columns != 'ID'].values # 입력 data\nlabels_input = labels_df.values  # 정답 data ","metadata":{"execution":{"iopub.status.busy":"2023-08-21T09:49:22.283827Z","iopub.execute_input":"2023-08-21T09:49:22.284208Z","iopub.status.idle":"2023-08-21T09:49:34.861966Z","shell.execute_reply.started":"2023-08-21T09:49:22.284177Z","shell.execute_reply":"2023-08-21T09:49:34.860581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 신경망 설계","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import LSTM, Conv1D, MaxPooling1D, Flatten, Dense, Bidirectional, Dropout, Add,Input, Embedding\nimport tensorflow as tf\n\n\n# Use MirroredStrategy for multi-GPU training\nstrategy = tf.distribute.MirroredStrategy()\nwith strategy.scope():\n    # Create a sequential model\n    model_CNN_LSTM = Sequential()\n    \n    # Add a Conv1D layer for spatial pattern detection\n    model_CNN_LSTM.add(Conv1D(32, kernel_size=3, input_shape = (1024,1), activation='relu'))\n    model_CNN_LSTM.add(MaxPooling1D(pool_size=2))\n    \n    # Add an LSTM layer for sequence modeling\n    model_CNN_LSTM.add(LSTM(units=64, dropout=0.2, recurrent_dropout=0.2))\n    \n    # Add another Dense layer for non-linear transformations\n    model_CNN_LSTM.add(Dense(128, activation='relu'))\n\n    # Add a fully connected layer for classification\n    model_CNN_LSTM.add(Dense(1500, activation='sigmoid'))\n    \n    # Compile the model\n    model_CNN_LSTM.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n    # Print the model summary\n    model_CNN_LSTM.summary()","metadata":{"execution":{"iopub.status.busy":"2023-08-21T09:49:55.177269Z","iopub.execute_input":"2023-08-21T09:49:55.177611Z","iopub.status.idle":"2023-08-21T09:49:55.623203Z","shell.execute_reply.started":"2023-08-21T09:49:55.177589Z","shell.execute_reply":"2023-08-21T09:49:55.621725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data loading 및 학습","metadata":{}},{"cell_type":"code","source":"# Use MirroredStrategy for multi-GPU training\nwith strategy.scope():\n    history_CNN = model_CNN_LSTM.fit(features_input, labels_input, epochs=20, batch_size=1024)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T09:51:49.021623Z","iopub.execute_input":"2023-08-21T09:51:49.021994Z","iopub.status.idle":"2023-08-21T09:52:07.827729Z","shell.execute_reply.started":"2023-08-21T09:51:49.021966Z","shell.execute_reply":"2023-08-21T09:52:07.825425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_df = pd.DataFrame(history_CNN.history)\n# Plot the loss with custom x-axis and y-axis range\nplt.figure(figsize=(10, 5))\nplt.plot(history_df['loss'])\nplt.title('Cross-entropy')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.xlim(0, len(history_df))  # Set x-axis range (epochs)\nplt.ylim(0, max(history_df['loss']))  # Set y-axis range (loss values)\nplt.show()\n\n# Plot the accuracy with custom x-axis and y-axis range\nplt.figure(figsize=(10, 5))\nplt.plot(history_df['accuracy'])\nplt.title('Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.xlim(0, len(history_df))  # Set x-axis range (epochs)\nplt.ylim(0, 1)  # Set y-axis range (accuracy values between 0 and 1)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 가중치 저장\nfrom tensorflow.keras.models import save_model\nmodel_CNN_LSTM.save(\"model_CNN_LSTM_ReLU_softmax.h5\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 가중치 불러오기\nfrom tensorflow.keras.models import load_model\nmodel_CNN_LSTM = load_model(\"/kaggle/input/cafa5-test/model_CNN_LSTM_softmax.h5\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train_terms \ndel train_embeddings\ndel train_id \ndel features_input\ndel labels_input \ndel labels_df\n\ngc_collect = gc.collect()\nprint(gc_collect)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 예측","metadata":{}},{"cell_type":"code","source":"# Test data 불러오기\ntest_protein_ids = np.load('/kaggle/input/t5embeds/test_ids.npy')\ntest_embeddings = np.load('/kaggle/input/t5embeds/test_embeds.npy')","metadata":{"execution":{"iopub.status.busy":"2023-08-21T10:04:44.647279Z","iopub.execute_input":"2023-08-21T10:04:44.647696Z","iopub.status.idle":"2023-08-21T10:04:55.897679Z","shell.execute_reply.started":"2023-08-21T10:04:44.647657Z","shell.execute_reply":"2023-08-21T10:04:55.896281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Embedding vector를 data frame으로 전환\ncolumn_num = test_embeddings.shape[1]\ntest_df = pd.DataFrame(test_embeddings, columns = [\"Column_\" + str(i) for i in range(1, column_num+1)])\nprint(test_df.shape)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T09:54:16.117686Z","iopub.execute_input":"2023-08-21T09:54:16.118152Z","iopub.status.idle":"2023-08-21T09:54:16.128004Z","shell.execute_reply.started":"2023-08-21T09:54:16.118116Z","shell.execute_reply":"2023-08-21T09:54:16.126121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions =  model_CNN_LSTM.predict(test_df)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T09:54:22.695528Z","iopub.execute_input":"2023-08-21T09:54:22.695904Z","iopub.status.idle":"2023-08-21T09:59:03.272137Z","shell.execute_reply.started":"2023-08-21T09:54:22.695875Z","shell.execute_reply":"2023-08-21T09:59:03.269671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prediction 데이터 저장\nwith open('predictions.pkl', 'wb') as predictions_file:\n    pickle.dump(predictions, predictions_file)\n\ndownload_file('/kaggle/working/predictions.pkl', 'predictions')","metadata":{"execution":{"iopub.status.busy":"2023-08-21T09:59:03.277997Z","iopub.execute_input":"2023-08-21T09:59:03.278486Z","iopub.status.idle":"2023-08-21T09:59:04.822204Z","shell.execute_reply.started":"2023-08-21T09:59:03.278444Z","shell.execute_reply":"2023-08-21T09:59:04.820100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predicion 데이터 불러오기\nwith open('/kaggle/input/predictions/predictions.pkl', 'rb') as predictions_file:\n    loaded_predictions = pickle.load(predictions_file)\nprint(loaded_predictions.shape)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T10:04:55.899659Z","iopub.execute_input":"2023-08-21T10:04:55.900070Z","iopub.status.idle":"2023-08-21T10:05:03.617062Z","shell.execute_reply.started":"2023-08-21T10:04:55.900031Z","shell.execute_reply":"2023-08-21T10:05:03.616030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 1500 개의 go term을 추린다.\nnum_of_labels = 1500\ntrain_terms = pd.read_csv('/kaggle/input/cafa-5-protein-function-prediction/Train/train_terms.tsv',sep='\\t')\nlabels = train_terms['term'].value_counts().index[:num_of_labels].tolist()","metadata":{"execution":{"iopub.status.busy":"2023-08-21T10:05:08.184400Z","iopub.execute_input":"2023-08-21T10:05:08.184841Z","iopub.status.idle":"2023-08-21T10:05:11.063006Z","shell.execute_reply.started":"2023-08-21T10:05:08.184807Z","shell.execute_reply":"2023-08-21T10:05:11.061887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"neural_network_df = pd.DataFrame(columns = ['Protein Id', 'GO Term Id','Prediction'])\n\nl = []\nfor k in list(test_protein_ids):\n    l += [ k] * loaded_predictions.shape[1]  \n\nneural_network_df['Protein Id'] = l\nneural_network_df['GO Term Id'] = labels * loaded_predictions.shape[0]\nneural_network_df['Prediction'] = loaded_predictions.ravel()\n\n# neural_network_df.to_csv(\"submission.tsv\",header=False, index=False, sep=\"\\t\")\n# Nueral network 예측 부분만 정답으로 사용하고 싶으면 위 코드를 실행 시키면 된다.","metadata":{"execution":{"iopub.status.busy":"2023-08-21T10:05:11.064999Z","iopub.execute_input":"2023-08-21T10:05:11.065406Z","iopub.status.idle":"2023-08-21T10:06:29.125840Z","shell.execute_reply.started":"2023-08-21T10:05:11.065370Z","shell.execute_reply":"2023-08-21T10:06:29.124855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(neural_network_df['Protein Id'].nunique(), len(neural_network_df))","metadata":{"execution":{"iopub.status.busy":"2023-08-21T10:06:29.127490Z","iopub.execute_input":"2023-08-21T10:06:29.127797Z","iopub.status.idle":"2023-08-21T10:06:42.203425Z","shell.execute_reply.started":"2023-08-21T10:06:29.127772Z","shell.execute_reply":"2023-08-21T10:06:42.202267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"selected_nn_df = neural_network_df[neural_network_df['Prediction'] > 0.64]\n\n# Print the selected rows\nprint(selected_nn_df['Protein Id'].nunique(), len(selected_nn_df)) # (0.64, 141864) // (0.65, 141795)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T10:41:54.965618Z","iopub.execute_input":"2023-08-21T10:41:54.966081Z","iopub.status.idle":"2023-08-21T10:41:55.904477Z","shell.execute_reply.started":"2023-08-21T10:41:54.966048Z","shell.execute_reply":"2023-08-21T10:41:55.902672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Answer Note\n- sequence vector distance와 neural network 예측을 합친다.","metadata":{}},{"cell_type":"code","source":"selected_vd_df = vector_distance_df[vector_distance_df['Prediction'] > 0.8]\nselected_nn_df = neural_network_df[neural_network_df['Prediction'] > 0.64]\n\nprint(selected_vd_df['Protein Id'].nunique(), len(selected_vd_df))\nprint(selected_nn_df['Protein Id'].nunique(), len(selected_nn_df))","metadata":{"execution":{"iopub.status.busy":"2023-08-21T12:34:47.528254Z","iopub.execute_input":"2023-08-21T12:34:47.529129Z","iopub.status.idle":"2023-08-21T12:34:48.009872Z","shell.execute_reply.started":"2023-08-21T12:34:47.529062Z","shell.execute_reply":"2023-08-21T12:34:48.008696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"selected_vd_df[selected_vd_df['Protein Id'] == 'Q9DCD0']","metadata":{"execution":{"iopub.status.busy":"2023-08-21T12:39:47.529789Z","iopub.execute_input":"2023-08-21T12:39:47.530246Z","iopub.status.idle":"2023-08-21T12:39:47.548446Z","shell.execute_reply.started":"2023-08-21T12:39:47.530214Z","shell.execute_reply":"2023-08-21T12:39:47.547217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"selected_nn_df.head())","metadata":{"execution":{"iopub.status.busy":"2023-08-21T12:34:48.960654Z","iopub.execute_input":"2023-08-21T12:34:48.961023Z","iopub.status.idle":"2023-08-21T12:34:48.972918Z","shell.execute_reply.started":"2023-08-21T12:34:48.960995Z","shell.execute_reply":"2023-08-21T12:34:48.971750Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"progress_bar = tqdm(total=len(selected_nn_df), desc=\"Converting to Dictionary\")\n\nselected_nn_dict = {}\nfor index, row in selected_nn_df.iterrows():\n    protein_id = row['Protein Id']\n    go_term_id = row['GO Term Id']\n    prediction = row['Prediction']\n    \n    if protein_id not in selected_nn_dict:\n        selected_nn_dict[protein_id] = {}\n    \n    selected_nn_dict[protein_id][go_term_id] = prediction\n    \n    progress_bar.update(1)  \n\nprogress_bar.close()\n\n#print(selected_nn_dict)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T12:35:08.223611Z","iopub.execute_input":"2023-08-21T12:35:08.223985Z","iopub.status.idle":"2023-08-21T12:35:27.911914Z","shell.execute_reply.started":"2023-08-21T12:35:08.223957Z","shell.execute_reply":"2023-08-21T12:35:27.910809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"progress_bar = tqdm(total=len(selected_vd_df), desc=\"Converting to Dictionary\")\n\nselected_vd_dict = {}\nfor index, row in selected_vd_df.iterrows():\n    protein_id = row['Protein Id']\n    go_term_id = row['GO Term Id']\n    prediction = row['Prediction']\n    \n    if protein_id not in selected_vd_dict:\n        selected_vd_dict[protein_id] = {}\n    \n    selected_vd_dict[protein_id][go_term_id] = prediction\n    \n    progress_bar.update(1)  \n\nprogress_bar.close()\n\n#print(selected_vd_dict)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T12:35:27.913858Z","iopub.execute_input":"2023-08-21T12:35:27.914178Z","iopub.status.idle":"2023-08-21T12:35:30.281419Z","shell.execute_reply.started":"2023-08-21T12:35:27.914150Z","shell.execute_reply":"2023-08-21T12:35:30.280265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vd_nn_dict = selected_nn_dict.copy()\n\n# Create a tqdm instance to track the progress\nprogress_bar = tqdm(total=len(selected_vd_dict), desc=\"Updating Dictionary\")\n\n# Iterate through the keys and nested dictionaries of selected_vd_dict and update selected_nn_dict\nfor protein_id in selected_vd_dict:\n    if protein_id in vd_nn_dict: #selected_nn_dict\n        for go_term_id, prediction in selected_vd_dict[protein_id].items():\n            if go_term_id in vd_nn_dict[protein_id]: #selected_nn_dict\n                vd_nn_dict[protein_id][go_term_id] = prediction #selected_nn_dict\n            else:\n                vd_nn_dict[protein_id][go_term_id] = prediction #selected_nn_dict\n    else:\n        vd_nn_dict[protein_id] = selected_vd_dict[protein_id]\n        #selected_nn_dict[protein_id] = selected_vd_dict[protein_id]\n    \n    progress_bar.update(1)  # Update the progress bar\n\n# Close the progress bar\nprogress_bar.close()\n\nprint(len(vd_nn_dict))","metadata":{"execution":{"iopub.status.busy":"2023-08-21T12:55:53.425617Z","iopub.execute_input":"2023-08-21T12:55:53.425999Z","iopub.status.idle":"2023-08-21T12:55:53.474925Z","shell.execute_reply.started":"2023-08-21T12:55:53.425963Z","shell.execute_reply":"2023-08-21T12:55:53.474080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out_file = \"/kaggle/working/submission.tsv\"  # Change extension to .tsv\n\ntry:\n    with open(out_file, 'w') as out:\n        for protein_ID in vd_nn_dict.keys():  # prediction.keys() == protein_IDs \n            go_terms_ri = vd_nn_dict[protein_ID]\n            for go_term in go_terms_ri.keys():\n                ri = go_terms_ri[go_term]\n                out.write('{}\\t{}\\t'.format(protein_ID, go_term))  # protein_ID, go_term\n                out.write('{:0.2f}\\n'.format(float(ri)))  # ri probability\n    print(f\"Data written to '{out_file}' successfully.\")\nexcept Exception as e:\n    print(\"An error occurred:\", e)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T12:55:59.207426Z","iopub.execute_input":"2023-08-21T12:55:59.207830Z","iopub.status.idle":"2023-08-21T12:55:59.814268Z","shell.execute_reply.started":"2023-08-21T12:55:59.207800Z","shell.execute_reply":"2023-08-21T12:55:59.813191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_path = \"/kaggle/working/submission.tsv\"\ndf = pd.read_csv(file_path, sep='\\t')\n\n# Display the DataFrame\nlen(df)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:17:12.897730Z","iopub.execute_input":"2023-08-21T13:17:12.898209Z","iopub.status.idle":"2023-08-21T13:17:13.088909Z","shell.execute_reply.started":"2023-08-21T13:17:12.898173Z","shell.execute_reply":"2023-08-21T13:17:13.087736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2023-08-21T14:13:58.741491Z","iopub.execute_input":"2023-08-21T14:13:58.743757Z","iopub.status.idle":"2023-08-21T14:13:58.859040Z","shell.execute_reply.started":"2023-08-21T14:13:58.743685Z","shell.execute_reply":"2023-08-21T14:13:58.857625Z"},"trusted":true},"execution_count":100,"outputs":[{"name":"stdout","text":"/kaggle/input/predictions/predictions.pkl\n/kaggle/input/vd-nn-submission/submission.tsv\n/kaggle/input/protbert-embeddings-for-cafa5/train_ids.npy\n/kaggle/input/protbert-embeddings-for-cafa5/train_embeddings.npy\n/kaggle/input/protbert-embeddings-for-cafa5/test_ids.npy\n/kaggle/input/protbert-embeddings-for-cafa5/test_embeddings.npy\n/kaggle/input/cafa-5-ems-2-embeddings-numpy/train_ids.npy\n/kaggle/input/cafa-5-ems-2-embeddings-numpy/train_embeddings.npy\n/kaggle/input/cafa-5-ems-2-embeddings-numpy/test_ids.npy\n/kaggle/input/cafa-5-ems-2-embeddings-numpy/test_embeddings.npy\n/kaggle/input/distance-tensor-con-0to15k/distance_tensor_0to15k.pkl\n/kaggle/input/labels-df/labels_df_ver1.pkl\n/kaggle/input/submission-1/submission_1.tsv\n/kaggle/input/submission-2/submission_2 .tsv\n/kaggle/input/distance-tensor-0to20k/distance_tensor_15000.pkl\n/kaggle/input/distance-tensor-0to20k/distance_tensor_5000.pkl\n/kaggle/input/distance-tensor-0to20k/distance_tensor_10000.pkl\n/kaggle/input/distance-tensor-0to20k/distance_tensor_0.pkl\n/kaggle/input/t5embeds/train_ids.npy\n/kaggle/input/t5embeds/test_embeds.npy\n/kaggle/input/t5embeds/train_embeds.npy\n/kaggle/input/t5embeds/test_ids.npy\n/kaggle/input/cafa-5-protein-function-prediction/sample_submission.tsv\n/kaggle/input/cafa-5-protein-function-prediction/IA.txt\n/kaggle/input/cafa-5-protein-function-prediction/Test (Targets)/testsuperset.fasta\n/kaggle/input/cafa-5-protein-function-prediction/Test (Targets)/testsuperset-taxon-list.tsv\n/kaggle/input/cafa-5-protein-function-prediction/Train/train_terms.tsv\n/kaggle/input/cafa-5-protein-function-prediction/Train/train_sequences.fasta\n/kaggle/input/cafa-5-protein-function-prediction/Train/train_taxonomy.tsv\n/kaggle/input/cafa-5-protein-function-prediction/Train/go-basic.obo\n/kaggle/input/dict-train-id-goterm/dict_train_id_go_term\n","output_type":"stream"}]},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/working/submission.tsv',\n    sep='\\t', header=None)\n\nsubmission.to_csv('submission.tsv',\n    sep='\\t', header=False, index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T14:14:18.570659Z","iopub.execute_input":"2023-08-21T14:14:18.571059Z","iopub.status.idle":"2023-08-21T14:14:19.531794Z","shell.execute_reply.started":"2023-08-21T14:14:18.571024Z","shell.execute_reply":"2023-08-21T14:14:19.530415Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2023-08-21T14:14:20.941079Z","iopub.execute_input":"2023-08-21T14:14:20.941461Z","iopub.status.idle":"2023-08-21T14:14:20.957263Z","shell.execute_reply.started":"2023-08-21T14:14:20.941432Z","shell.execute_reply":"2023-08-21T14:14:20.956293Z"},"trusted":true},"execution_count":102,"outputs":[{"execution_count":102,"output_type":"execute_result","data":{"text/plain":"                 0           1     2\n0           Q9CQV8  GO:0005575  0.66\n1           Q9CQV8  GO:0110165  0.65\n2           P62259  GO:0005575  0.65\n3           P62259  GO:0110165  0.64\n4           P62259  GO:0050815  1.00\n...            ...         ...   ...\n319835      C0HK73  GO:0110165  0.64\n319836      C0HK74  GO:0005575  0.66\n319837      C0HK74  GO:0110165  0.65\n319838  A0A3G2FQK2  GO:0005575  0.66\n319839  A0A3G2FQK2  GO:0110165  0.64\n\n[319840 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Q9CQV8</td>\n      <td>GO:0005575</td>\n      <td>0.66</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Q9CQV8</td>\n      <td>GO:0110165</td>\n      <td>0.65</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>P62259</td>\n      <td>GO:0005575</td>\n      <td>0.65</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>P62259</td>\n      <td>GO:0110165</td>\n      <td>0.64</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>P62259</td>\n      <td>GO:0050815</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>319835</th>\n      <td>C0HK73</td>\n      <td>GO:0110165</td>\n      <td>0.64</td>\n    </tr>\n    <tr>\n      <th>319836</th>\n      <td>C0HK74</td>\n      <td>GO:0005575</td>\n      <td>0.66</td>\n    </tr>\n    <tr>\n      <th>319837</th>\n      <td>C0HK74</td>\n      <td>GO:0110165</td>\n      <td>0.65</td>\n    </tr>\n    <tr>\n      <th>319838</th>\n      <td>A0A3G2FQK2</td>\n      <td>GO:0005575</td>\n      <td>0.66</td>\n    </tr>\n    <tr>\n      <th>319839</th>\n      <td>A0A3G2FQK2</td>\n      <td>GO:0110165</td>\n      <td>0.64</td>\n    </tr>\n  </tbody>\n</table>\n<p>319840 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}